import streamlit as st
import pandas as pd
import numpy as np
import requests
import subprocess
import os
from dotenv import load_dotenv
import sys
from datetime import datetime
import json
import base64
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

    
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=IBM+Plex+Serif:wght@400;700&display=swap');
    .stDataFrame {
        font-size: 12px;
    }
    .stDataFrame table {
        width: 100% !important;
    }
    .stDataFrame td, .stDataFrame th {
        white-space: nowrap !important;
        overflow: visible !important;
        text-overflow: clip !important;
        max-width: none !important;
        min-width: 120px !important;
    }
    .pivot-table {
        background-color: #f8f9fa;
        padding: 10px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .metric-card {
        background-color: #e9ecef;
        padding: 15px;
        border-radius: 8px;
        margin: 5px 0;
        text-align: center;
    }
    .sparkline {
        height: 30px;
        margin: 0;
        padding: 0;
    }
    .category-header {
        background-color: #eaf6ff;          /* unify with table cells */
        padding: 12px 15px;
        border-radius: 6px;
        margin: 8px 0 12px 0;
        border-left: 6px solid #1f77b4;
        font-weight: bold;
        font-size: 1.25rem;
        font-family: "IBM Plex Serif", "Times New Roman", serif;
    }
    .sub-category {
        padding-left: 20px;
        margin: 2px 0;
    }
    .positive-change {
        color: #28a745 !important;
        font-weight: bold !important;
        background-color: rgba(40, 167, 69, 0.1) !important;
        padding: 2px 4px !important;
        border-radius: 3px !important;
    }
    .negative-change {
        color: #dc3545 !important;
        font-weight: bold !important;
        background-color: rgba(220, 53, 69, 0.1) !important;
        padding: 2px 4px !important;
        border-radius: 3px !important;
    }
    .no-change {
        color: #6c757d !important;
        font-weight: bold !important;
        background-color: rgba(108, 117, 125, 0.1) !important;
        padding: 2px 4px !important;
        border-radius: 3px !important;
    }
    .full-width-table {
        overflow-x: auto;
        width: 100%;
        position: relative;
    }
    .full-width-table table {
        min-width: 100%;
        table-layout: auto;
    }
    .full-width-table td {
        white-space: nowrap;
        padding: 8px 12px;
        min-width: 150px;
    }
    /* Pivot table font */
    .full-width-table table,
    .full-width-table td,
    .full-width-table th {
        font-family: "IBM Plex Serif", "Times New Roman", serif;
    }
    .full-width-table th:first-child,
    .full-width-table td:first-child {
        position: sticky;
        left: 0;
        background-color: #f8f9fa;
        z-index: 10;
        border-right: 2px solid #dee2e6;
        min-width: 250px !important;
        max-width: 500px !important;
        font-family: "IBM Plex Serif", "Times New Roman", serif;
    }
    .full-width-table th:last-child,
    .full-width-table td:last-child {
        position: sticky;
        right: 0;
        background-color: #e9ecef;
        z-index: 10;
        border-left: 2px solid #dee2e6;
        font-weight: bold;
        min-width: 120px !important;
    }
    .number-cell {
        text-align: right;
        font-family: 'Courier New', monospace;
        font-weight: bold;
    }
    
    /* Mobile optimizations */
    @media (max-width: 768px) {
        .main .block-container {
            padding: 0.5rem;
        }
        
        .stButton > button {
            width: 100%;
            margin: 2px 0;
        }
        
        .stDataFrame {
            font-size: 10px;
        }
    }
    
    /* Upload section styles */
    .upload-section {
        background: #f8f9fa;
        padding: 15px;
        border-radius: 10px;
        margin: 10px 0;
    }
    
    .status-indicator {
        display: inline-block;
        width: 10px;
        height: 10px;
        border-radius: 50%;
        margin-right: 8px;
    }
    
    .status-online { background-color: #28a745; }
    .status-loading { background-color: #ffc107; }
    .status-offline { background-color: #dc3545; }
</style>
""", unsafe_allow_html=True)

# ================== DATA MANAGER CLASS ==================
class DataManager:
    """
    Qu·∫£n l√Ω d·ªØ li·ªáu v·ªõi GitHub storage
    - Load/Save t·ª´ GitHub
    - Auto backup
    - Optimized cho storage
    """
    
    def __init__(self):
        self.github_token = st.secrets.get("github_token", None)
        self.github_owner = st.secrets.get("github_owner", None)
        self.github_repo = st.secrets.get("github_repo", None)
        
        # File naming strategy
        self.current_data_file = "current_dashboard_data.json"
        self.metadata_file = "upload_metadata.json"
        self.backup_prefix = "backup_"
        
        # Settings
        self.keep_backups = 2
        self.max_file_size_mb = 25
    
    def check_github_connection(self):
        """Ki·ªÉm tra k·∫øt n·ªëi GitHub"""
        if not all([self.github_token, self.github_owner, self.github_repo]):
            return False, "‚ùå Ch∆∞a c·∫•u h√¨nh GitHub credentials"
        
        try:
            url = f"https://api.github.com/repos/{self.github_owner}/{self.github_repo}"
            headers = {"Authorization": f"token {self.github_token}"}
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                return True, "‚úÖ GitHub k·∫øt n·ªëi th√†nh c√¥ng"
            else:
                return False, f"‚ùå GitHub error: {response.status_code}"
                
        except Exception as e:
            return False, f"‚ùå L·ªói k·∫øt n·ªëi: {str(e)}"
    
    def get_current_file_info(self):
        """L·∫•y th√¥ng tin file hi·ªán t·∫°i"""
        try:
            metadata_url = f"https://api.github.com/repos/{self.github_owner}/{self.github_repo}/contents/{self.metadata_file}"
            headers = {"Authorization": f"token {self.github_token}"}
            
            response = requests.get(metadata_url, headers=headers)
            
            if response.status_code == 200:
                file_data = response.json()
                content = base64.b64decode(file_data['content']).decode()
                metadata = json.loads(content)
                return metadata
            
        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ ƒë·ªçc metadata: {str(e)}")
        
        return None
    
    def create_backup_of_current_file(self):
        """Backup file hi·ªán t·∫°i tr∆∞·ªõc khi x√≥a"""
        try:
            current_url = f"https://api.github.com/repos/{self.github_owner}/{self.github_repo}/contents/{self.current_data_file}"
            headers = {"Authorization": f"token {self.github_token}"}
            
            response = requests.get(current_url, headers=headers)
            
            if response.status_code == 200:
                file_data = response.json()
                
                current_metadata = self.get_current_file_info()
                if current_metadata:
                    upload_time = current_metadata.get('upload_time', datetime.now().isoformat())
                    backup_timestamp = upload_time[:19].replace(':', '-').replace(' ', '_')
                else:
                    backup_timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
                
                backup_filename = f"{self.backup_prefix}{backup_timestamp}.json"
                
                backup_url = f"https://api.github.com/repos/{self.github_owner}/{self.github_repo}/contents/{backup_filename}"
                
                backup_payload = {
                    "message": f"üì¶ Backup before new upload - {backup_timestamp}",
                    "content": file_data['content'],
                    "branch": "main"
                }
                
                backup_response = requests.put(backup_url, headers=headers, json=backup_payload)
                
                if backup_response.status_code == 201:
                    st.info(f"üì¶ ƒê√£ backup file c≈©: {backup_filename}")
                    return backup_filename
                    
        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ backup file c≈©: {str(e)}")
        
        return None
    
    def cleanup_old_backups(self):
        """X√≥a c√°c backup c≈©, ch·ªâ gi·ªØ l·∫°i s·ªë l∆∞·ª£ng nh·∫•t ƒë·ªãnh"""
        try:
            contents_url = f"https://api.github.com/repos/{self.github_owner}/{self.github_repo}/contents"
            headers = {"Authorization": f"token {self.github_token}"}
            
            response = requests.get(contents_url, headers=headers)
            
            if response.status_code == 200:
                files = response.json()
                
                backup_files = [f for f in files if f['name'].startswith(self.backup_prefix)]
                backup_files.sort(key=lambda x: x['name'], reverse=True)
                files_to_delete = backup_files[self.keep_backups:]
                
                deleted_count = 0
                for file_to_delete in files_to_delete:
                    try:
                        delete_url = f"https://api.github.com/repos/{self.github_owner}/{self.github_repo}/contents/{file_to_delete['name']}"
                        
                        delete_payload = {
                            "message": f"üóëÔ∏è Auto cleanup old backup: {file_to_delete['name']}",
                            "sha": file_to_delete['sha'],
                            "branch": "main"
                        }
                        
                        delete_response = requests.delete(delete_url, headers=headers, json=delete_payload)
                        
                        if delete_response.status_code == 200:
                            deleted_count += 1
                            
                    except Exception as e:
                        continue
                
                if deleted_count > 0:
                    st.info(f"üóëÔ∏è ƒê√£ x√≥a {deleted_count} backup c≈©")
                    
        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ cleanup backups: {str(e)}")
    
    def upload_new_file(self, data, filename):
        """Upload file m·ªõi v·ªõi auto-cleanup"""
        
        try:
            connected, message = self.check_github_connection()
            if not connected:
                st.error(message)
                return False
            
            st.info("üîÑ B·∫Øt ƒë·∫ßu upload file m·ªõi...")
            
            with st.spinner("üì¶ ƒêang backup file c≈©..."):
                backup_filename = self.create_backup_of_current_file()
            
            with st.spinner("üìä ƒêang chu·∫©n b·ªã d·ªØ li·ªáu..."):
                new_data_package = {
                    'data': data.to_dict('records'),
                    'columns': list(data.columns),
                    'metadata': {
                        'filename': filename,
                        'upload_time': datetime.now().isoformat(),
                        'week_number': datetime.now().isocalendar()[1],
                        'year': datetime.now().year,
                        'row_count': len(data),
                        'file_size_mb': round(len(str(data)) / (1024*1024), 2),
                        'uploader': 'admin',
                        'replaced_backup': backup_filename
                    }
                }
                
                json_content = json.dumps(new_data_package, ensure_ascii=False, indent=2)
                size_mb = len(json_content.encode()) / (1024*1024)
                
                if size_mb > self.max_file_size_mb:
                    st.error(f"‚ùå File qu√° l·ªõn ({size_mb:.1f}MB). Gi·ªõi h·∫°n {self.max_file_size_mb}MB")
                    return False
            
            with st.spinner("‚òÅÔ∏è ƒêang upload file m·ªõi..."):
                content_encoded = base64.b64encode(json_content.encode()).decode()
                
                current_url = f"https://api.github.com/repos/{self.github_owner}/{self.github_repo}/contents/{self.current_data_file}"
                headers = {"Authorization": f"token {self.github_token}"}
                
                current_response = requests.get(current_url, headers=headers)
                current_sha = None
                if current_response.status_code == 200:
                    current_sha = current_response.json()['sha']
                
                upload_payload = {
                    "message": f"üìä Data update - Tu·∫ßn {new_data_package['metadata']['week_number']}/{new_data_package['metadata']['year']}",
                    "content": content_encoded,
                    "branch": "main"
                }
                
                if current_sha:
                    upload_payload["sha"] = current_sha
                
                upload_response = requests.put(current_url, headers=headers, json=upload_payload)
                
                if upload_response.status_code not in [200, 201]:
                    st.error(f"‚ùå L·ªói upload: {upload_response.status_code}")
                    return False
            
            with st.spinner("üìù ƒêang c·∫≠p nh·∫≠t metadata..."):
                self.update_metadata(new_data_package['metadata'])
            
            with st.spinner("üóëÔ∏è ƒêang d·ªçn d·∫πp backup c≈©..."):
                self.cleanup_old_backups()
            
            st.success(f"""
            üéâ **UPLOAD TH√ÄNH C√îNG!**
            
            ‚úÖ **File m·ªõi:** {filename}
            ‚úÖ **D·ªØ li·ªáu:** {len(data):,} d√≤ng ({size_mb:.1f}MB)
            ‚úÖ **Tu·∫ßn:** {new_data_package['metadata']['week_number']}/{new_data_package['metadata']['year']}
            ‚úÖ **Backup:** {backup_filename if backup_filename else 'Kh√¥ng c√≥ file c≈©'}
            
            üì± **D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u tr√™n cloud!**
            """)
            
            return True
            
        except Exception as e:
            st.error(f"‚ùå L·ªói upload: {str(e)}")
            return False
    
    def update_metadata(self, metadata):
        """C·∫≠p nh·∫≠t file metadata"""
        try:
            metadata_url = f"https://api.github.com/repos/{self.github_owner}/{self.github_repo}/contents/{self.metadata_file}"
            headers = {"Authorization": f"token {self.github_token}"}
            
            current_response = requests.get(metadata_url, headers=headers)
            current_sha = None
            if current_response.status_code == 200:
                current_sha = current_response.json()['sha']
            
            metadata_content = json.dumps(metadata, ensure_ascii=False, indent=2)
            content_encoded = base64.b64encode(metadata_content.encode()).decode()
            
            payload = {
                "message": f"üìù Update metadata - Tu·∫ßn {metadata['week_number']}/{metadata['year']}",
                "content": content_encoded,
                "branch": "main"
            }
            
            if current_sha:
                payload["sha"] = current_sha
            
            requests.put(metadata_url, headers=headers, json=payload)
            
        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ update metadata: {str(e)}")
    
    def load_current_data(self):
        """Load d·ªØ li·ªáu hi·ªán t·∫°i"""
        try:
            current_url = f"https://api.github.com/repos/{self.github_owner}/{self.github_repo}/contents/{self.current_data_file}"
            headers = {"Authorization": f"token {self.github_token}"}
            
            response = requests.get(current_url, headers=headers)
            
            if response.status_code == 200:
                file_data = response.json()
                content = base64.b64decode(file_data['content']).decode()
                data_package = json.loads(content)
                
                df = pd.DataFrame(data_package['data'], columns=data_package['columns'])
                
                return df, data_package['metadata']
            
        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ load d·ªØ li·ªáu: {str(e)}")
        
        return None, None
    
    def get_storage_info(self):
        """L·∫•y th√¥ng tin storage usage"""
        try:
            contents_url = f"https://api.github.com/repos/{self.github_owner}/{self.github_repo}/contents"
            headers = {"Authorization": f"token {self.github_token}"}
            
            response = requests.get(contents_url, headers=headers)
            
            if response.status_code == 200:
                files = response.json()
                
                total_size = sum(f.get('size', 0) for f in files)
                backup_files = [f for f in files if f['name'].startswith(self.backup_prefix)]
                
                return {
                    'total_files': len(files),
                    'backup_files': len(backup_files),
                    'total_size_mb': round(total_size / (1024*1024), 2),
                    'files': files
                }
                
        except Exception as e:
            pass
        
        return None

# ================== PIVOT TABLE DASHBOARD CLASS (FULL ORIGINAL) ==================
class PivotTableDashboard:
    def __init__(self):
        self.data = None
        
        # C·∫§U H√åNH TH·ª® T·ª∞ ∆ØU TI√äN C·ªê ƒê·ªäNH THEO Y√äU C·∫¶U M·ªöI
        self.category_priority = {
            "VƒÉn b·∫£n ƒë·∫øn": 1,
            "VƒÉn b·∫£n ph√°t h√†nh": 2,
            "ChƒÉm s√≥c kh√°ch vip": 3,
            "L·ªÖ t√¢n": 4,
            "Ti·∫øp kh√°ch trong n∆∞·ªõc": 5,
            "S·ª± ki·ªán": 6,
            "ƒê√≥n ti·∫øp kh√°ch VIP": 7,
            "T·ªï ch·ª©c cu·ªôc h·ªçp tr·ª±c tuy·∫øn": 8,
            "Trang ƒëi·ªÅu h√†nh t√°c nghi·ªáp": 9,
            "T·ªï xe": 10,
            "T·ªïng ƒë√†i": 11,
            "H·ªá th·ªëng th∆∞ k√Ω B·ªánh vi·ªán": 12,
            "B√£i gi·ªØ xe": 13
        }
        
        self.content_priority = {
            # VƒÉn b·∫£n ƒë·∫øn
            "T·ªïng s·ªë vƒÉn b·∫£n ƒë·∫øn, trong ƒë√≥:": 1,
            "S·ªë vƒÉn b·∫£n kh√¥ng y√™u c·∫ßu ph·∫£n h·ªìi": 2,
            "S·ªë vƒÉn b·∫£n y√™u c·∫ßu ph·∫£n h·ªìi": 3,
            "X·ª≠ l√Ω ƒë√∫ng h·∫°n": 4,
            "X·ª≠ l√Ω tr·ªÖ h·∫°n": 5,
            
            # VƒÉn b·∫£n ph√°t h√†nh
            "VƒÉn b·∫£n ƒëi": 6,
            "H·ª£p ƒë·ªìng": 7,
            "Quy·∫øt ƒë·ªãnh": 8,
            "Quy ch·∫ø": 9,
            "Quy ƒë·ªãnh": 10,
            "Quy tr√¨nh": 11,
            
            # ChƒÉm s√≥c kh√°ch vip
            "Ti·∫øp ƒë√≥n, h∆∞·ªõng d·∫´n v√† ph·ª•c v·ª• kh√°ch VIP": 12,
            
            # L·ªÖ t√¢n
            "H·ªó tr·ª£ l·ªÖ t√¢n cho h·ªôi ngh·ªã/h·ªôi th·∫£o": 13,
            
            # Ti·∫øp kh√°ch trong n∆∞·ªõc
            "T·ªïng s·ªë ƒëo√†n kh√°ch trong n∆∞·ªõc, trong ƒë√≥:": 14,
            "Tham quan, h·ªçc t·∫≠p": 15,
            "L√†m vi·ªác": 16,
            
            # S·ª± ki·ªán
            "T·ªïng s·ªë s·ª± ki·ªán h√†nh ch√≠nh c·ªßa B·ªánh vi·ªán, trong ƒë√≥:": 17,
            "Ph√≤ng H√†nh ch√≠nh ch·ªß tr√¨": 18,
            "Ph√≤ng H√†nh ch√≠nh ph·ªëi h·ª£p": 19,
            
            # ƒê√≥n ti·∫øp kh√°ch VIP
            "S·ªë l∆∞·ª£t kh√°ch VIP ƒë∆∞·ª£c l·ªÖ t√¢n ti·∫øp ƒë√≥n, h·ªó tr·ª£ kh√°m ch·ªØa b·ªánh": 20,
            
            # T·ªï ch·ª©c cu·ªôc h·ªçp tr·ª±c tuy·∫øn
            "T·ªïng s·ªë cu·ªôc h·ªçp tr·ª±c tuy·∫øn do Ph√≤ng H√†nh ch√≠nh chu·∫©n b·ªã": 21,
            
            # Trang ƒëi·ªÅu h√†nh t√°c nghi·ªáp
            "S·ªë l∆∞·ª£ng tin ƒëƒÉng ƒêHTN": 22,
            
            # T·ªï xe
            "S·ªë chuy·∫øn xe": 23,
            "T·ªïng s·ªë nhi√™n li·ªáu ti√™u th·ª•": 24,
            "T·ªïng km ch·∫°y": 25,
            "Xe h√†nh ch√≠nh": 26,
            "Xe c·ª©u th∆∞∆°ng": 27,
            "Chi ph√≠ b·∫£o d∆∞·ª°ng": 28,
            "Doanh thu": 29,
            "T·ªï xe": 30,
            "S·ªë phi·∫øu kh·∫£o s√°t h√†i l√≤ng": 31,
            "T·ª∑ l·ªá h√†i l√≤ng c·ªßa kh√°ch h√†ng": 32,
            
            # T·ªïng ƒë√†i
            "T·ªïng s·ªë cu·ªôc g·ªçi ƒë·∫øn B·ªánh vi·ªán": 33,
            "T·ªïng s·ªë cu·ªôc g·ªçi nh·ª° do t·ª´ ch·ªëi": 34,
            "T·ªïng s·ªë cu·ªôc g·ªçi nh·ª° do kh√¥ng b·∫Øt m√°y": 35,
            "S·ªë cu·ªôc g·ªçi ƒë·∫øn (Nh√°nh 0-T·ªïng ƒë√†i vi√™n)": 36,
            "Nh·ª° do t·ª´ ch·ªëi (Nh√°nh 0-T·ªïng ƒë√†i vi√™n)": 37,
            "Nh·ª° do kh√¥ng b·∫Øt m√°y (Nh√°nh 0-T·ªïng ƒë√†i vi√™n)": 38,
            "S·ªë cu·ªôc g·ªçi ƒë·∫øn (Nh√°nh 1-C·∫•p c·ª©u)": 39,
            "Nh·ª° do t·ª´ ch·ªëi (Nh√°nh 1-C·∫•p c·ª©u)": 40,
            "Nh·ª° do kh√¥ng b·∫Øt m√°y (Nh√°nh 1-C·∫•p c·ª©u)": 41,
            "S·ªë cu·ªôc g·ªçi ƒë·∫øn (Nh√°nh 2-T∆∞ v·∫•n Thu·ªëc)": 42,
            "Nh·ª° do t·ª´ ch·ªëi (Nh√°nh 2- T∆∞ v·∫•n Thu·ªëc)": 43,
            "Nh·ª° do kh√¥ng b·∫Øt m√°y (Nh√°nh 2-T∆∞ v·∫•n Thu·ªëc)": 44,
            "S·ªë cu·ªôc g·ªçi ƒë·∫øn (Nh√°nh 3-PKQT)": 45,
            "Nh·ª° do t·ª´ ch·ªëi (Nh√°nh 3-PKQT)": 46,
            "Nh·ª° do kh√¥ng b·∫Øt m√°y  (Nh√°nh 3-PKQT)": 47,
            "S·ªë cu·ªôc g·ªçi ƒë·∫øn (Nh√°nh 4-V·∫•n ƒë·ªÅ kh√°c)": 48,
            "Nh·ª° do t·ª´ ch·ªëi (Nh√°nh 4-V·∫•n ƒë·ªÅ kh√°c)": 49,
            "Nh·ª° do kh√¥ng b·∫Øt m√°y (Nh√°nh 4-V·∫•n ƒë·ªÅ kh√°c)": 50,
            "Hottline": 51,
            
            # H·ªá th·ªëng th∆∞ k√Ω B·ªánh vi·ªán
            "S·ªë th∆∞ k√Ω ƒë∆∞·ª£c s∆° tuy·ªÉn": 52,
            "S·ªë th∆∞ k√Ω ƒë∆∞·ª£c tuy·ªÉn d·ª•ng": 53,
            "S·ªë th∆∞ k√Ω nh·∫≠n vi·ªác": 54,
            "S·ªë th∆∞ k√Ω ngh·ªâ vi·ªác": 55,
            "S·ªë th∆∞ k√Ω ƒë∆∞·ª£c ƒëi·ªÅu ƒë·ªông": 56,
            "T·ªïng s·ªë th∆∞ k√Ω": 57,
            "- Th∆∞ k√Ω h√†nh ch√≠nh": 58,
            "- Th∆∞ k√Ω chuy√™n m√¥n": 59,
            "S·ªë bu·ªïi sinh ho·∫°t cho th∆∞ k√Ω": 60,
            "S·ªë th∆∞ k√Ω tham gia sinh ho·∫°t": 61,
            "S·ªë bu·ªïi t·∫≠p hu·∫•n, ƒë√†o t·∫°o cho th∆∞ k√Ω": 62,
            "S·ªë th∆∞ k√Ω tham gia t·∫≠p hu·∫•n, ƒë√†o t·∫°o": 63,
            "S·ªë bu·ªïi tham quan, h·ªçc t·∫≠p": 64,
            "S·ªë th∆∞ k√Ω tham gia tham quan, h·ªçc t·∫≠p": 65,
            # ======= TH√äM C√ÅC BI·∫æN TH·ªÇ C√ì TH·ªÇ =======
            # Bi·∫øn th·ªÉ c√≥ kho·∫£ng tr·∫Øng th·ª´a
            " T·ªïng s·ªë th∆∞ k√Ω": 57,
            "T·ªïng s·ªë th∆∞ k√Ω ": 57,
            " T·ªïng s·ªë th∆∞ k√Ω ": 57,
            
            # Bi·∫øn th·ªÉ c√≥ k√Ω t·ª± ƒë·∫∑c bi·ªát
            "T·ªïng s·ªë th∆∞ k√Ω:": 57,
            "- T·ªïng s·ªë th∆∞ k√Ω": 57,
            "‚Ä¢ T·ªïng s·ªë th∆∞ k√Ω": 57,
            
            # Bi·∫øn th·ªÉ vi·∫øt hoa/th∆∞·ªùng
            "T·ªîNG S·ªê TH∆Ø K√ù": 57,
            "t·ªïng s·ªë th∆∞ k√Ω": 57,
            
            # Bi·∫øn th·ªÉ t·ª´ kh√≥a t∆∞∆°ng t·ª±
            "T·ªëng s·ªë th∆∞ k√Ω": 57,  # Typo c√≥ th·ªÉ
            "T·ªïng s·ªë th∆∞ k√≠": 57,  # K√Ω/k√≠
            "T·ªïng th∆∞ k√Ω": 57,     # Thi·∫øu "s·ªë"
            # =========================================
            # B√£i gi·ªØ xe
            "T·ªïng s·ªë l∆∞·ª£t v√© ng√†y": 66,
            "T·ªïng s·ªë l∆∞·ª£t v√© th√°ng": 67,
            "C√¥ng su·∫•t trung b√¨nh/ng√†y": 68,
            "Doanh thu": 69,
            "S·ªë ph·∫£n √°nh khi·∫øu n·∫°i": 70
        }
        self.content_aggregation = {
        # TRUNG B√åNH - Cho c√°c t·ª∑ l·ªá %
        "T·ª∑ l·ªá h√†i l√≤ng c·ªßa kh√°ch h√†ng": "mean",
        "T·ª∑ l·ªá h√†i l√≤ng kh√°ch h√†ng": "mean",  # Bi·∫øn th·ªÉ
        "Ty le hai long cua khach hang": "mean",  # Bi·∫øn th·ªÉ kh√¥ng d·∫•u
        
        # D·ªÆ LI·ªÜU M·ªöI NH·∫§T - Cho c√°c ch·ªâ s·ªë t·ªïng s·ªë (snapshot)
        "T·ªïng s·ªë th∆∞ k√Ω": "last",
        "- Th∆∞ k√Ω h√†nh ch√≠nh": "last", 
        "- Th∆∞ k√Ω chuy√™n m√¥n": "last",
        "Th∆∞ k√Ω h√†nh ch√≠nh": "last",
        "Th∆∞ k√Ω chuy√™n m√¥n": "last",
        " Th∆∞ k√Ω h√†nh ch√≠nh": "last",  # Bi·∫øn th·ªÉ c√≥ space
        " Th∆∞ k√Ω chuy√™n m√¥n": "last",
        
        # C√≥ th·ªÉ th√™m c√°c n·ªôi dung kh√°c c·∫ßn x·ª≠ l√Ω ƒë·∫∑c bi·ªát
        "C√¥ng su·∫•t trung b√¨nh/ng√†y": "mean",  # C√¥ng su·∫•t l√† trung b√¨nh
        "C√¥ng su·∫•t trung b√¨nh": "mean",
        
        # C√°c ch·ªâ s·ªë t√†i ch√≠nh c√≥ th·ªÉ c·∫ßn l·∫•y m·ªõi nh·∫•t
        "Doanh thu": "sum",  # Doanh thu th√¨ c·ªông d·ªìn
        "Chi ph√≠ b·∫£o d∆∞·ª°ng": "sum",  # Chi ph√≠ th√¨ c·ªông d·ªìn
        
        # DEFAULT: T·∫•t c·∫£ c√°c n·ªôi dung kh√°c s·∫Ω d√πng 'sum'
    }
    
    def get_aggregation_method(self, content):
        """L·∫•y ph∆∞∆°ng ph√°p aggregation ph√π h·ª£p cho n·ªôi dung"""
        if pd.isna(content):
            return "sum"
        
        # Th·ª≠ t√™n ch√≠nh x√°c
        if content in self.content_aggregation:
            return self.content_aggregation[content]
        
        # Th·ª≠ t√™n ƒë√£ chu·∫©n h√≥a ƒë∆°n gi·∫£n
        normalized = str(content).strip().strip('- ‚Ä¢:')
        if normalized in self.content_aggregation:
            return self.content_aggregation[normalized]
        
        # Th·ª≠ t√¨m b·∫±ng keyword
        content_lower = str(content).lower().strip()
        
        # T·ª∑ l·ªá % -> mean
        if any(keyword in content_lower for keyword in ['t·ª∑ l·ªá', 'ty le', '%', 'ph·∫ßn trƒÉm']):
            return "mean"
        
        # T·ªïng s·ªë th∆∞ k√Ω -> last
        if any(keyword in content_lower for keyword in ['t·ªïng s·ªë', 'tong so']) and 'th∆∞ k√Ω' in content_lower:
            return "last"
        
        # Th∆∞ k√Ω con -> last
        if any(keyword in content_lower for keyword in ['th∆∞ k√Ω h√†nh ch√≠nh', 'th∆∞ k√Ω chuy√™n m√¥n', 'thu ky hanh chinh', 'thu ky chuyen mon']):
            return "last"
        
        # Trung b√¨nh -> mean
        if any(keyword in content_lower for keyword in ['trung b√¨nh', 'trung binh', 'tb']):
            return "mean"
        
        # M·∫∑c ƒë·ªãnh: sum
        return "sum"

    def apply_smart_aggregation(self, data, index_cols, column_cols, value_col):
        """√Åp d·ª•ng aggregation th√¥ng minh theo t·ª´ng n·ªôi dung"""
        try:
            # Group d·ªØ li·ªáu theo index v√† columns
            if column_cols:
                group_cols = index_cols + column_cols
            else:
                group_cols = index_cols
            
            # T·∫°o dictionary ƒë·ªÉ store aggregated data
            result_data = []
            
            # Group theo c√°c c·ªôt c·∫ßn thi·∫øt
            for group_keys, group_data in data.groupby(group_cols):
                if not isinstance(group_keys, tuple):
                    group_keys = (group_keys,)
                
                # T·∫°o dict cho group n√†y
                result_row = {}
                
                # Assign index values
                for i, col in enumerate(group_cols):
                    result_row[col] = group_keys[i]
                
                # L·∫•y n·ªôi dung ƒë·ªÉ x√°c ƒë·ªãnh aggregation method
                if 'N·ªôi dung' in group_data.columns:
                    content = group_data['N·ªôi dung'].iloc[0]
                    agg_method = self.get_aggregation_method(content)
                    
                    # √Åp d·ª•ng aggregation method
                    if agg_method == "mean":
                        result_row[value_col] = group_data[value_col].mean()
                    elif agg_method == "last":
                        # L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t (tu·∫ßn cao nh·∫•t)
                        if 'Tu·∫ßn' in group_data.columns:
                            latest_week_data = group_data[group_data['Tu·∫ßn'] == group_data['Tu·∫ßn'].max()]
                            result_row[value_col] = latest_week_data[value_col].iloc[-1]
                        else:
                            result_row[value_col] = group_data[value_col].iloc[-1]
                    else:  # sum (default)
                        result_row[value_col] = group_data[value_col].sum()
                else:
                    # Fallback to sum
                    result_row[value_col] = group_data[value_col].sum()
                
                result_data.append(result_row)
            
            # Convert back to DataFrame
            result_df = pd.DataFrame(result_data)
            
            # Create pivot table
            if column_cols:
                pivot = pd.pivot_table(
                    result_df,
                    index=index_cols,
                    columns=column_cols,
                    values=value_col,
                    aggfunc='first',  # Data ƒë√£ ƒë∆∞·ª£c aggregate r·ªìi
                    fill_value=0
                )
            else:
                pivot = result_df.set_index(index_cols)[value_col]
            
            return pivot
            
        except Exception as e:
            st.error(f"L·ªói trong smart aggregation: {str(e)}")
            # Fallback to normal pivot
            return pd.pivot_table(
                data,
                index=index_cols,
                columns=column_cols if column_cols else None,
                values=value_col,
                aggfunc='sum',
                fill_value=0
            )    
        
    def load_data_from_dataframe(self, df):
        """TH√äM METHOD M·ªöI: Load d·ªØ li·ªáu t·ª´ DataFrame"""
        try:
            self.data = df.copy()
            
            # L√†m s·∫°ch t√™n c·ªôt
            self.data.columns = self.data.columns.str.strip()
            
            # Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu
            self.data['Tu·∫ßn'] = pd.to_numeric(self.data['Tu·∫ßn'], errors='coerce')
            self.data['Th√°ng'] = pd.to_numeric(self.data['Th√°ng'], errors='coerce')
            self.data['S·ªë li·ªáu'] = pd.to_numeric(self.data['S·ªë li·ªáu'], errors='coerce')
            
            # Th√™m c·ªôt nƒÉm (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh theo d·ªØ li·ªáu th·ª±c t·∫ø)
            if 'NƒÉm' not in self.data.columns:
                self.data['NƒÉm'] = datetime.now().year
            
            # T·∫°o c·ªôt Qu√Ω t·ª´ Th√°ng
            self.data['Qu√Ω'] = ((self.data['Th√°ng'] - 1) // 3) + 1
            
            # T·∫°o c·ªôt k·∫øt h·ª£p ƒë·ªÉ d·ªÖ filter
            self.data['Th√°ng_NƒÉm'] = self.data.apply(lambda x: f"T{int(x['Th√°ng'])}/{int(x['NƒÉm'])}", axis=1)
            self.data['Tu·∫ßn_Th√°ng'] = self.data.apply(lambda x: f"W{int(x['Tu·∫ßn'])}-T{int(x['Th√°ng'])}", axis=1)
            
            # √ÅP D·ª§NG TH·ª® T·ª∞ ∆ØU TI√äN
            self._apply_priority_order()
            
            # T√çNH T·ª∂ L·ªÜ SO V·ªöI TU·∫¶N TR∆Ø·ªöC
            self._calculate_week_over_week_ratio()
            
            return True
            
        except Exception as e:
            st.error(f"L·ªói khi x·ª≠ l√Ω DataFrame: {str(e)}")
            return False

    def load_data(self, file):
        """
        Load data directly from an Excel file (desktop path, BytesIO, or Streamlit
        UploadedFile object) and then process it via `load_data_from_dataframe`.

        Parameters
        ----------
        file : str | pathlib.Path | file‚Äëlike
            The file path or file‚Äëlike object pointing to an Excel workbook.

        Returns
        -------
        bool
            True if the data was loaded and processed successfully, otherwise False.
        """
        try:
            # Pandas can read from both file paths and file‚Äëlike objects
            df = pd.read_excel(file)
            return self.load_data_from_dataframe(df)
        except Exception as e:
            st.error(f"L·ªói khi ƒë·ªçc file Excel: {str(e)}")
            return False
    
    def _apply_priority_order(self):
        """√Åp d·ª•ng th·ª© t·ª± ∆∞u ti√™n cho danh m·ª•c v√† n·ªôi dung"""
        # Th√™m c·ªôt th·ª© t·ª± ∆∞u ti√™n cho danh m·ª•c
        self.data['Danh_m·ª•c_th·ª©_t·ª±'] = self.data['Danh m·ª•c'].map(self.category_priority)
        
        # Th√™m c·ªôt th·ª© t·ª± ∆∞u ti√™n cho n·ªôi dung
        self.data['N·ªôi_dung_th·ª©_t·ª±'] = self.data['N·ªôi dung'].map(self.content_priority)
        
        # G√°n th·ª© t·ª± cao (999) cho c√°c danh m·ª•c/n·ªôi dung kh√¥ng c√≥ trong danh s√°ch ∆∞u ti√™n
        self.data['Danh_m·ª•c_th·ª©_t·ª±'] = self.data['Danh_m·ª•c_th·ª©_t·ª±'].fillna(999)
        self.data['N·ªôi_dung_th·ª©_t·ª±'] = self.data['N·ªôi_dung_th·ª©_t·ª±'].fillna(999)
        
        # S·∫Øp x·∫øp d·ªØ li·ªáu theo th·ª© t·ª± ∆∞u ti√™n
        self.data = self.data.sort_values([
            'Danh_m·ª•c_th·ª©_t·ª±', 
            'N·ªôi_dung_th·ª©_t·ª±', 
            'NƒÉm', 
            'Th√°ng', 
            'Tu·∫ßn'
        ]).reset_index(drop=True)
    
    def _calculate_week_over_week_ratio(self):
        """T√≠nh t·ª∑ l·ªá so v·ªõi tu·∫ßn tr∆∞·ªõc - LOGIC M·ªöI"""
        # Kh·ªüi t·∫°o c·ªôt
        self.data['T·ª∑_l·ªá_tu·∫ßn_tr∆∞·ªõc'] = None
        self.data['Thay_ƒë·ªïi_tu·∫ßn_tr∆∞·ªõc'] = None
        
        # Group theo danh m·ª•c v√† n·ªôi dung, sau ƒë√≥ t√≠nh bi·∫øn ƒë·ªông
        for (category, content), group in self.data.groupby(['Danh m·ª•c', 'N·ªôi dung']):
            # S·∫Øp x·∫øp theo nƒÉm, th√°ng, tu·∫ßn
            group_sorted = group.sort_values(['NƒÉm', 'Th√°ng', 'Tu·∫ßn']).reset_index()
            
            # B·ªè qua tu·∫ßn ƒë·∫ßu ti√™n (kh√¥ng c√≥ tu·∫ßn tr∆∞·ªõc ƒë·ªÉ so s√°nh)
            for i in range(1, len(group_sorted)):
                current_idx = group_sorted.loc[i, 'index']  # index g·ªëc trong data
                current_value = group_sorted.loc[i, 'S·ªë li·ªáu']
                previous_value = group_sorted.loc[i-1, 'S·ªë li·ªáu']
                
                # T√≠nh bi·∫øn ƒë·ªông
                if pd.notna(current_value) and pd.notna(previous_value):
                    if previous_value != 0:
                        # C√¥ng th·ª©c: (tu·∫ßn hi·ªán t·∫°i - tu·∫ßn tr∆∞·ªõc) / tu·∫ßn tr∆∞·ªõc * 100
                        ratio = ((current_value - previous_value) / previous_value) * 100
                        change = current_value - previous_value
                        
                        self.data.loc[current_idx, 'T·ª∑_l·ªá_tu·∫ßn_tr∆∞·ªõc'] = ratio
                        self.data.loc[current_idx, 'Thay_ƒë·ªïi_tu·∫ßn_tr∆∞·ªõc'] = change
                    elif previous_value == 0 and current_value > 0:
                        # TƒÉng t·ª´ 0 l√™n s·ªë d∆∞∆°ng
                        self.data.loc[current_idx, 'T·ª∑_l·ªá_tu·∫ßn_tr∆∞·ªõc'] = 999.0  # V√¥ h·∫°n
                        self.data.loc[current_idx, 'Thay_ƒë·ªïi_tu·∫ßn_tr∆∞·ªõc'] = current_value
                    # Tr∆∞·ªùng h·ª£p kh√°c (0->0, ho·∫∑c gi√° tr·ªã √¢m) gi·ªØ None
    
    def create_pivot_settings(self):
        """T·∫°o c√†i ƒë·∫∑t cho pivot table"""
        st.sidebar.header("‚öôÔ∏è C√†i ƒë·∫∑t Pivot Table")
        
        # Ch·ªçn ki·ªÉu b√°o c√°o
        report_type = st.sidebar.selectbox(
            "Ki·ªÉu b√°o c√°o",
            ["Theo Tu·∫ßn", "T√πy ch·ªânh"]
        )
        
        # Ch·ªçn d√≤ng v√† c·ªôt cho pivot
        col1, col2 = st.sidebar.columns(2)
        
        available_dims = ['Tu·∫ßn', 'Th√°ng', 'Qu√Ω', 'NƒÉm', 'Danh m·ª•c', 'N·ªôi dung']
        
        with col1:
            rows = st.multiselect(
                "Ch·ªçn d√≤ng (Rows)",
                available_dims,
                default=['Danh m·ª•c'] if report_type == "T√πy ch·ªânh" else self._get_default_rows(report_type)
            )
        
        with col2:
            cols = st.multiselect(
                "Ch·ªçn c·ªôt (Columns)",
                [dim for dim in available_dims if dim not in rows],
                default=self._get_default_cols(report_type)
            )
        
        # Ch·ªçn gi√° tr·ªã v√† ph√©p t√≠nh
        values = st.sidebar.selectbox(
            "Gi√° tr·ªã hi·ªÉn th·ªã",
            ["S·ªë li·ªáu"]
        )
        
        agg_func = st.sidebar.selectbox(
            "Ph√©p t√≠nh",
            ["sum", "mean", "count", "min", "max"],
            format_func=lambda x: {
                'sum': 'T·ªïng',
                'mean': 'Trung b√¨nh',
                'count': 'ƒê·∫øm',
                'min': 'Nh·ªè nh·∫•t',
                'max': 'L·ªõn nh·∫•t'
            }.get(x, x)
        )
        
        # Hi·ªÉn th·ªã bi·∫øn ƒë·ªông g·ªôp v√†o gi√° tr·ªã
        show_ratio_inline = st.sidebar.checkbox("Hi·ªÉn th·ªã bi·∫øn ƒë·ªông trong gi√° tr·ªã", value=True)
        
        return report_type, rows, cols, values, agg_func, show_ratio_inline
    
    def _get_default_rows(self, report_type):
        """L·∫•y d√≤ng m·∫∑c ƒë·ªãnh theo ki·ªÉu b√°o c√°o"""
        defaults = {
            "Theo Tu·∫ßn": ['Danh m·ª•c', 'N·ªôi dung'],
            "Theo Th√°ng": ['Danh m·ª•c'],
            "Theo Qu√Ω": ['Danh m·ª•c'],
            "Theo NƒÉm": ['Danh m·ª•c']
        }
        return defaults.get(report_type, ['Danh m·ª•c'])
    
    def _get_default_cols(self, report_type):
        """L·∫•y c·ªôt m·∫∑c ƒë·ªãnh theo ki·ªÉu b√°o c√°o"""
        defaults = {
            "Theo Tu·∫ßn": ['Tu·∫ßn'],
            "Theo Th√°ng": ['Th√°ng'],
            "Theo Qu√Ω": ['Qu√Ω'],
            "Theo NƒÉm": ['NƒÉm']
        }
        return defaults.get(report_type, ['Th√°ng'])
    
    def create_filters(self):
        """T·∫°o b·ªô l·ªçc d·ªØ li·ªáu"""
        st.sidebar.header("üîç L·ªçc d·ªØ li·ªáu")

        # ----- KHUNG TH·ªúI GIAN: T·ª™ ... ƒê·∫æN ... -----
        years = sorted(self.data['NƒÉm'].unique())
        months_list = list(range(1, 13))
        weeks_list = list(range(1, 53))

        st.sidebar.subheader("‚è±Ô∏è T·ª´ (From)")
        from_year = st.sidebar.selectbox("NƒÉm b·∫Øt ƒë·∫ßu", years, index=0, key="from_year")
        from_month = st.sidebar.selectbox("Th√°ng b·∫Øt ƒë·∫ßu", months_list, index=0, key="from_month")
        from_week = st.sidebar.selectbox("Tu·∫ßn b·∫Øt ƒë·∫ßu", weeks_list, index=0, key="from_week")

        st.sidebar.subheader("‚è±Ô∏è ƒê·∫øn (To)")
        to_year = st.sidebar.selectbox("NƒÉm k·∫øt th√∫c", years, index=len(years) - 1, key="to_year")
        to_month = st.sidebar.selectbox("Th√°ng k·∫øt th√∫c", months_list, index=11, key="to_month")
        to_week = st.sidebar.selectbox("Tu·∫ßn k·∫øt th√∫c", weeks_list, index=51, key="to_week")

        # -------- CH·ªåN DANH M·ª§C --------
        unique_categories = self.data['Danh m·ª•c'].unique()
        sorted_categories = sorted(unique_categories,
                                   key=lambda x: self.category_priority.get(x, 999))

        selected_categories = []
        with st.sidebar.expander("üìÇ Ch·ªçn danh m·ª•c", expanded=True):
            select_all = st.checkbox("Ch·ªçn t·∫•t c·∫£ danh m·ª•c", value=True, key="select_all_cat")
            if select_all:
                selected_categories = list(sorted_categories)
            else:
                for category in sorted_categories:
                    category_selected = st.checkbox(f"üìÅ {category}", value=False, key=f"cat_{category}")
                    if category_selected:
                        selected_categories.append(category)

        return from_year, from_month, from_week, to_year, to_month, to_week, selected_categories
    
    def filter_data(self, from_year, from_month, from_week, to_year, to_month, to_week, categories):
        """L·ªçc d·ªØ li·ªáu theo kho·∫£ng tu·∫ßn‚Äìth√°ng‚ÄìnƒÉm"""
        filtered = self.data.copy()

        # ƒêi·ªÅu ki·ªán b·∫Øt ƒë·∫ßu
        cond_start = (
            (filtered['NƒÉm'] > from_year) |
            ((filtered['NƒÉm'] == from_year) & (filtered['Th√°ng'] > from_month)) |
            ((filtered['NƒÉm'] == from_year) & (filtered['Th√°ng'] == from_month) & (filtered['Tu·∫ßn'] >= from_week))
        )

        # ƒêi·ªÅu ki·ªán k·∫øt th√∫c
        cond_end = (
            (filtered['NƒÉm'] < to_year) |
            ((filtered['NƒÉm'] == to_year) & (filtered['Th√°ng'] < to_month)) |
            ((filtered['NƒÉm'] == to_year) & (filtered['Th√°ng'] == to_month) & (filtered['Tu·∫ßn'] <= to_week))
        )

        filtered = filtered[cond_start & cond_end & (filtered['Danh m·ª•c'].isin(categories))]

        return filtered
    
    def aggregate_data_by_report_type(self, data, report_type):
        """T·ª± ƒë·ªông aggregate d·ªØ li·ªáu theo lo·∫°i b√°o c√°o"""
        if report_type == "Theo Tu·∫ßn":
            # Gi·ªØ nguy√™n d·ªØ li·ªáu tu·∫ßn
            return data
        
        elif report_type == "Theo Th√°ng":
            # Aggregate theo th√°ng
            aggregated = data.groupby([
                'Danh m·ª•c', 'N·ªôi dung', 'NƒÉm', 'Th√°ng', 'Qu√Ω',
                'Danh_m·ª•c_th·ª©_t·ª±', 'N·ªôi_dung_th·ª©_t·ª±'
            ]).agg({
                'S·ªë li·ªáu': 'sum'  # T·ªïng theo th√°ng
            }).reset_index()
            
            # T·∫°o l·∫°i c√°c c·ªôt c·∫ßn thi·∫øt
            aggregated['Th√°ng_NƒÉm'] = aggregated.apply(lambda x: f"T{int(x['Th√°ng'])}/{int(x['NƒÉm'])}", axis=1)
            
            # Kh√¥ng t√≠nh bi·∫øn ƒë·ªông cho aggregate theo th√°ng (c√≥ th·ªÉ th√™m sau)
            aggregated['T·ª∑_l·ªá_tu·∫ßn_tr∆∞·ªõc'] = None
            aggregated['Thay_ƒë·ªïi_tu·∫ßn_tr∆∞·ªõc'] = None
            
            return aggregated
        
        elif report_type == "Theo Qu√Ω":
            # Aggregate theo qu√Ω
            aggregated = data.groupby([
                'Danh m·ª•c', 'N·ªôi dung', 'NƒÉm', 'Qu√Ω',
                'Danh_m·ª•c_th·ª©_t·ª±', 'N·ªôi_dung_th·ª©_t·ª±'
            ]).agg({
                'S·ªë li·ªáu': 'sum'  # T·ªïng theo qu√Ω
            }).reset_index()
            
            # Kh√¥ng t√≠nh bi·∫øn ƒë·ªông cho aggregate theo qu√Ω
            aggregated['T·ª∑_l·ªá_tu·∫ßn_tr∆∞·ªõc'] = None
            aggregated['Thay_ƒë·ªïi_tu·∫ßn_tr∆∞·ªõc'] = None
            
            return aggregated
        
        elif report_type == "Theo NƒÉm":
            # Aggregate theo nƒÉm
            aggregated = data.groupby([
                'Danh m·ª•c', 'N·ªôi dung', 'NƒÉm',
                'Danh_m·ª•c_th·ª©_t·ª±', 'N·ªôi_dung_th·ª©_t·ª±'
            ]).agg({
                'S·ªë li·ªáu': 'sum'  # T·ªïng theo nƒÉm
            }).reset_index()
            
            # Kh√¥ng t√≠nh bi·∫øn ƒë·ªông cho aggregate theo nƒÉm
            aggregated['T·ª∑_l·ªá_tu·∫ßn_tr∆∞·ªõc'] = None
            aggregated['Thay_ƒë·ªïi_tu·∫ßn_tr∆∞·ªõc'] = None
            
            return aggregated
        
        else:  # T√πy ch·ªânh
            return data
    
    def format_value_with_change(self, value, ratio, change):
        """ƒê·ªãnh d·∫°ng gi√° tr·ªã v·ªõi bi·∫øn ƒë·ªông inline - C·∫¢I TI·∫æN ƒê·ªÇ HI·ªÇN TH·ªä R√ï R√ÄNG H∆†N"""
        # ƒê·∫£m b·∫£o hi·ªÉn th·ªã s·ªë ƒë·∫ßy ƒë·ªß
        value_str = f"{value:,.0f}".replace(',', '.')
        
        if pd.isna(ratio) or ratio == 0:
            return value_str
        
        if ratio == 999:  # V√¥ h·∫°n
            return f"{value_str} <span class='positive-change'>‚Üë‚àû%</span>"
        
        if ratio > 0:
            symbol = "‚Üë"
            color_class = "positive-change"
        elif ratio < 0:
            symbol = "‚Üì"  
            color_class = "negative-change"
        else:
            symbol = "‚Üí"
            color_class = "no-change"
            
        ratio_text = f"{abs(ratio):.1f}%"
        
        # FORMAT R√ï R√ÄNG: s·ªë (bi·∫øn ƒë·ªông)
        return f"{value_str} <span class='{color_class}'>({symbol}{ratio_text})</span>"
    
    def create_hierarchical_pivot_table_with_ratio(self, data, rows, cols, values, agg_func, show_ratio_inline):
        try:
            if not rows and not cols:
                st.warning("Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt chi·ªÅu cho d√≤ng ho·∫∑c c·ªôt")
                return None
            
            # ƒê·∫£m b·∫£o d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp theo th·ª© t·ª± ∆∞u ti√™n
            if 'Danh m·ª•c' in rows:
                data = data.sort_values(['Danh_m·ª•c_th·ª©_t·ª±', 'N·ªôi_dung_th·ª©_t·ª±'])
            
            # ========== S·ª¨ D·ª§NG SMART AGGREGATION ==========
            # T·∫°o pivot table cho gi√° tr·ªã ch√≠nh
            if cols:
                pivot = self.apply_smart_aggregation(data, rows, cols, values)
                
                # ============= S·∫ÆP X·∫æP C·ªòT TU·∫¶N GI·∫¢M D·∫¶N =============
                if 'Tu·∫ßn' in cols and hasattr(pivot, 'columns'):
                    # L·∫•y danh s√°ch c·ªôt hi·ªán t·∫°i
                    current_columns = list(pivot.columns)
                    
                    # T√°ch c·ªôt tu·∫ßn v√† c·ªôt kh√°c
                    week_columns = []
                    other_columns = []
                    
                    for col in current_columns:
                        try:
                            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† s·ªë tu·∫ßn kh√¥ng
                            week_num = int(str(col).strip())
                            if 1 <= week_num <= 53:  # Tu·∫ßn h·ª£p l·ªá
                                week_columns.append(col)
                            else:
                                other_columns.append(col)
                        except (ValueError, TypeError):
                            other_columns.append(col)
                    
                    # S·∫Øp x·∫øp tu·∫ßn theo th·ª© t·ª± GI·∫¢M D·∫¶N (tu·∫ßn cao nh·∫•t tr∆∞·ªõc)
                    week_columns_sorted = sorted(week_columns, key=lambda x: int(str(x)), reverse=True)
                    
                    # T√°i t·∫°o th·ª© t·ª± c·ªôt: tu·∫ßn (gi·∫£m d·∫ßn) + c·ªôt kh√°c
                    new_column_order = week_columns_sorted + other_columns
                    
                    # Reindex pivot table v·ªõi th·ª© t·ª± m·ªõi
                    pivot = pivot.reindex(columns=new_column_order)
                    
                    st.sidebar.info(f"üìÖ Hi·ªÉn th·ªã t·ª´ tu·∫ßn {max(week_columns)} ‚Üí tu·∫ßn {min(week_columns)}")
                # ====================================================
                
                # S·ª≠a l·ªói mixed column types
                if isinstance(pivot.columns, pd.MultiIndex):
                    pivot.columns = pivot.columns.map(str)
                else:
                    pivot.columns = [str(col) for col in pivot.columns]
                        
            else:
                pivot = self.apply_smart_aggregation(data, rows, None, values)
            # ===============================================
            
            # N·∫øu c·∫ßn hi·ªÉn th·ªã bi·∫øn ƒë·ªông inline (CH·ªà CHO B√ÅO C√ÅO THEO TU·∫¶N)
            if show_ratio_inline and cols and 'Tu·∫ßn' in cols:
                # L·ªçc d·ªØ li·ªáu c√≥ bi·∫øn ƒë·ªông
                ratio_data = data[pd.notna(data['T·ª∑_l·ªá_tu·∫ßn_tr∆∞·ªõc'])].copy()
                
                if not ratio_data.empty:
                    try:
                        # T·∫°o pivot table cho gi√° tr·ªã g·ªëc v·ªõi smart aggregation
                        main_pivot = self.apply_smart_aggregation(data, rows, cols, 'S·ªë li·ªáu')
                        
                        # ============= S·∫ÆP X·∫æP C·ªòT CHO MAIN_PIVOT =============
                        if hasattr(main_pivot, 'columns'):
                            current_columns = list(main_pivot.columns)
                            week_columns = []
                            other_columns = []
                            
                            for col in current_columns:
                                try:
                                    week_num = int(str(col).strip())
                                    if 1 <= week_num <= 53:
                                        week_columns.append(col)
                                    else:
                                        other_columns.append(col)
                                except (ValueError, TypeError):
                                    other_columns.append(col)
                            
                            # S·∫Øp x·∫øp tu·∫ßn gi·∫£m d·∫ßn
                            week_columns_sorted = sorted(week_columns, key=lambda x: int(str(x)), reverse=True)
                            new_column_order = week_columns_sorted + other_columns
                            
                            main_pivot = main_pivot.reindex(columns=new_column_order)
                        # ====================================================
                        
                        # T·∫°o pivot table cho t·ª∑ l·ªá bi·∫øn ƒë·ªông
                        ratio_pivot = pd.pivot_table(
                            ratio_data,
                            index=rows if rows else None,
                            columns=cols,
                            values='T·ª∑_l·ªá_tu·∫ßn_tr∆∞·ªõc',
                            aggfunc='mean',
                            fill_value=None
                        )
                        
                        # ============= S·∫ÆP X·∫æP C·ªòT CHO RATIO_PIVOT =============
                        if hasattr(ratio_pivot, 'columns'):
                            current_columns = list(ratio_pivot.columns)
                            week_columns = []
                            other_columns = []
                            
                            for col in current_columns:
                                try:
                                    week_num = int(str(col).strip())
                                    if 1 <= week_num <= 53:
                                        week_columns.append(col)
                                    else:
                                        other_columns.append(col)
                                except (ValueError, TypeError):
                                    other_columns.append(col)
                            
                            week_columns_sorted = sorted(week_columns, key=lambda x: int(str(x)), reverse=True)
                            new_column_order = week_columns_sorted + other_columns
                            
                            ratio_pivot = ratio_pivot.reindex(columns=new_column_order)
                        # ====================================================
                        
                        # T·∫°o combined pivot v·ªõi bi·∫øn ƒë·ªông
                        combined_pivot = main_pivot.copy()
                        
                        # √Åp d·ª•ng bi·∫øn ƒë·ªông cho t·ª´ng √¥
                        for idx in main_pivot.index:
                            for col in main_pivot.columns:
                                main_value = main_pivot.loc[idx, col]
                                
                                # Ki·ªÉm tra c√≥ bi·∫øn ƒë·ªông kh√¥ng
                                if idx in ratio_pivot.index and col in ratio_pivot.columns:
                                    ratio_val = ratio_pivot.loc[idx, col]
                                    if pd.notna(ratio_val):
                                        # C√≥ bi·∫øn ƒë·ªông - format v·ªõi %
                                        combined_pivot.loc[idx, col] = self.format_value_with_change(main_value, ratio_val, 0)
                                        continue
                                
                                # Kh√¥ng c√≥ bi·∫øn ƒë·ªông - ch·ªâ hi·ªÉn th·ªã s·ªë
                                combined_pivot.loc[idx, col] = f"{main_value:,.0f}".replace(',', '.')
                        
                        # TH√äM C·ªòT T·ªîNG - SMART AGGREGATION
                        combined_pivot['T·ªïng'] = ""
                        for idx in combined_pivot.index:
                            # L·∫•y n·ªôi dung ƒë·ªÉ x√°c ƒë·ªãnh c√°ch t√≠nh t·ªïng
                            if isinstance(idx, tuple) and len(idx) > 1:
                                content = idx[1]  # N·ªôi dung th∆∞·ªùng ·ªü v·ªã tr√≠ th·ª© 2
                            else:
                                content = str(idx)
                            
                            agg_method = self.get_aggregation_method(content)
                            
                            row_total = 0
                            row_count = 0
                            
                            for col in main_pivot.columns:
                                val = main_pivot.loc[idx, col]
                                if pd.notna(val) and val != 0:
                                    if agg_method == "mean":
                                        row_total += float(val)
                                        row_count += 1
                                    elif agg_method == "last":
                                        # V·ªõi 'last', l·∫•y gi√° tr·ªã m·ªõi nh·∫•t (c·ªôt ƒë·∫ßu ti√™n)
                                        row_total = float(val)
                                        break
                                    else:  # sum
                                        row_total += float(val)
                            
                            # Format t·ªïng
                            if agg_method == "mean" and row_count > 0:
                                avg_value = row_total / row_count
                                combined_pivot.loc[idx, 'T·ªïng'] = f"{avg_value:,.1f}".replace(',', '.')
                            else:
                                combined_pivot.loc[idx, 'T·ªïng'] = f"{row_total:,.0f}".replace(',', '.')
                        
                        return combined_pivot
                        
                    except Exception as e:
                        st.sidebar.error(f"L·ªói t·∫°o bi·∫øn ƒë·ªông: {str(e)}")
                        pass
            
            # N·∫øu kh√¥ng c√≥ bi·∫øn ƒë·ªông - format s·ªë ƒë·∫πp v√† th√™m c·ªôt t·ªïng
            if isinstance(pivot, pd.DataFrame):
                pivot_formatted = pivot.copy()
                
                # Format t·∫•t c·∫£ s·ªë th√†nh d·∫°ng ƒë·∫πp
                for idx in pivot_formatted.index:
                    for col in pivot_formatted.columns:
                        val = pivot.loc[idx, col]
                        if pd.notna(val):
                            pivot_formatted.loc[idx, col] = f"{val:,.1f}".replace(',', '.')
                
                # TH√äM C·ªòT T·ªîNG - SMART AGGREGATION
                pivot_formatted['T·ªïng'] = ""
                for idx in pivot_formatted.index:
                    # L·∫•y n·ªôi dung ƒë·ªÉ x√°c ƒë·ªãnh c√°ch t√≠nh t·ªïng
                    if isinstance(idx, tuple) and len(idx) > 1:
                        content = idx[1]  # N·ªôi dung th∆∞·ªùng ·ªü v·ªã tr√≠ th·ª© 2
                    else:
                        content = str(idx)
                    
                    agg_method = self.get_aggregation_method(content)
                    
                    row_total = 0
                    row_count = 0
                    
                    for col in pivot.columns:
                        val = pivot.loc[idx, col]
                        if pd.notna(val) and val != 0:
                            if agg_method == "mean":
                                row_total += float(val)
                                row_count += 1
                            elif agg_method == "last":
                                # V·ªõi 'last', l·∫•y gi√° tr·ªã m·ªõi nh·∫•t (c·ªôt ƒë·∫ßu ti√™n)
                                row_total = float(val)
                                break
                            else:  # sum
                                row_total += float(val)
                    
                    # Format t·ªïng
                    if agg_method == "mean" and row_count > 0:
                        avg_value = row_total / row_count
                        pivot_formatted.loc[idx, 'T·ªïng'] = f"{avg_value:,.1f}".replace(',', '.')
                    elif agg_method == "last":
                        pivot_formatted.loc[idx, 'T·ªïng'] = f"{row_total:,.0f}".replace(',', '.')
                    else:
                        pivot_formatted.loc[idx, 'T·ªïng'] = f"{row_total:,.0f}".replace(',', '.')
                
                return pivot_formatted
            
            return pivot
            
        except Exception as e:
            st.error(f"L·ªói t·∫°o pivot table: {str(e)}")
            return None

    def display_category_sparklines(self, category_data, category_name, report_type):
        """Hi·ªÉn th·ªã sparklines cho t·ª´ng n·ªôi dung trong danh m·ª•c"""
        try:
            if not isinstance(category_data, pd.DataFrame):
                return
            
            # T·∫°o sparklines cho t·ª´ng n·ªôi dung trong danh m·ª•c
            col1, col2, col3 = st.columns([3, 2, 1])
            with col1:
                st.markdown("**N·ªôi dung**")
            with col2:
                st.markdown("**Xu h∆∞·ªõng**")
            with col3:
                st.markdown("**T·ªïng h√†ng**")
            
            for content in category_data.index:
                # L·∫•y d·ªØ li·ªáu cho n·ªôi dung n√†y
                content_values = []
                for col in category_data.columns:
                    val = category_data.loc[content, col]
                    if isinstance(val, str):
                        # Extract s·ªë t·ª´ HTML
                        import re
                        numbers = re.findall(r'[\d.]+', val.replace('.', ''))
                        if numbers:
                            content_values.append(int(numbers[0].replace('.', '')))
                        else:
                            content_values.append(0)
                    else:
                        content_values.append(val if pd.notna(val) else 0)
                
                # T·∫°o sparkline
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    y=content_values,
                    mode='lines+markers',
                    line=dict(width=2, color='royalblue'),
                    marker=dict(size=3),
                    showlegend=False
                ))
                
                # Highlight max/min
                if content_values and max(content_values) > 0:
                    max_idx = np.argmax(content_values)
                    min_idx = np.argmin(content_values)
                    
                    fig.add_trace(go.Scatter(
                        x=[max_idx], y=[content_values[max_idx]],
                        mode='markers', marker=dict(size=5, color='green'),
                        showlegend=False
                    ))
                    fig.add_trace(go.Scatter(
                        x=[min_idx], y=[content_values[min_idx]],
                        mode='markers', marker=dict(size=5, color='red'),
                        showlegend=False
                    ))
                
                fig.update_layout(
                    margin=dict(l=0, r=0, t=0, b=0),
                    height=40, width=200,
                    paper_bgcolor='rgba(0,0,0,0)',
                    plot_bgcolor='rgba(0,0,0,0)',
                    xaxis=dict(showticklabels=False, showgrid=False, zeroline=False),
                    yaxis=dict(showticklabels=False, showgrid=False, zeroline=False),
                    hovermode=False
                )
                
                # T√≠nh t·ªïng h√†ng
                row_total = sum(content_values)
                
                # Hi·ªÉn th·ªã
                col1, col2, col3 = st.columns([3, 2, 1])
                with col1:
                    st.markdown(f"üìÑ {content}")
                with col2:
                    st.plotly_chart(fig, use_container_width=True, key=f"spark_{category_name}_{content}")
                with col3:
                    st.markdown(f"**{row_total:,.0f}**".replace(',', '.'))
                    
        except Exception as e:
            st.error(f"L·ªói t·∫°o sparkline cho {category_name}: {str(e)}")
    
    def display_hierarchical_pivot_improved(self, pivot, data):
        """Hi·ªÉn th·ªã pivot table v·ªõi c·∫•u tr√∫c ph√¢n c·∫•p c·∫£i ti·∫øn - Sparkline ·ªü d∆∞·ªõi c√πng"""
        if pivot is None:
            return
        
        # Ki·ªÉm tra xem c√≥ ph·∫£i pivot table v·ªõi Danh m·ª•c kh√¥ng
        if isinstance(pivot.index, pd.MultiIndex) and 'Danh m·ª•c' in pivot.index.names:
            # Hi·ªÉn th·ªã theo c·∫•u tr√∫c ph√¢n c·∫•p
            
            # L·∫•y danh s√°ch c√°c danh m·ª•c theo th·ª© t·ª± ∆∞u ti√™n
            categories = pivot.index.get_level_values('Danh m·ª•c').unique()
            sorted_categories = sorted(categories, key=lambda x: self.category_priority.get(x, 999))
            
            # PH·∫¶N 1: HI·ªÇN TH·ªä PIVOT TABLE CHO T·ª™NG DANH M·ª§C
            for category in sorted_categories:
                # Expander without label; we'll render a custom styled header inside
                with st.expander("", expanded=True):
                    # Category title: bigger, bold, subtle background
                    st.markdown(f"<div class='category-header'>üìÅ {category}</div>", unsafe_allow_html=True)
                    # L·ªçc d·ªØ li·ªáu cho danh m·ª•c n√†y
                    category_data = pivot.xs(category, level='Danh m·ª•c')
                    
                    # S·∫Øp x·∫øp theo th·ª© t·ª± ∆∞u ti√™n n·ªôi dung
                    if isinstance(category_data.index, pd.Index):
                        # L·∫•y danh s√°ch n·ªôi dung v√† s·∫Øp x·∫øp
                        contents = category_data.index.tolist()
                        sorted_contents = sorted(contents, key=lambda x: self.content_priority.get(x, 999))
                        category_data = category_data.reindex(sorted_contents)
                    
                    # HI·ªÇN TH·ªä B·∫¢NG D·ªÆ LI·ªÜU
                    if isinstance(category_data, pd.DataFrame):
                        # T·∫°o HTML table ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß s·ªë
                        html_table = "<div class='full-width-table'>"
                        html_table += "<table style='width:100%; border-collapse: collapse; font-size: 15px;'>"
                        
                        # Header
                        html_table += "<tr style='background-color: #f0f2f6;'>"
                        html_table += "<th style='border: 1px solid #ddd; padding: 8px; text-align: left; min-width: 250px; position: sticky; left: 0; background-color: #f0f2f6; z-index: 10;'>N·ªôi dung</th>"
                        for col in category_data.columns:
                            if col == 'T·ªïng':
                                html_table += f"<th style='border: 1px solid #ddd; padding: 8px; text-align: center; min-width: 120px; position: sticky; right: 0; background-color: #f0f2f6; z-index: 10; font-weight: bold;'>{col}</th>"
                            else:
                                html_table += f"<th style='border: 1px solid #ddd; padding: 8px; text-align: center; min-width: 150px;'>{col}</th>"
                        html_table += "</tr>"
                        
                        # Data rows
                        for content in category_data.index:
                            html_table += "<tr>"
                            html_table += f"<td style='border: 1px solid #ddd; padding: 8px; font-weight: bold; position: sticky; left: 0; background-color: #f8f9fa; z-index: 10;'>{content}</td>"
                            
                            for col in category_data.columns:
                                value = category_data.loc[content, col]
                                if col == 'T·ªïng':
                                    html_table += f"<td style='border: 1px solid #ddd; padding: 8px; text-align: right; position: sticky; right: 0; background-color: #e9ecef; z-index: 10; font-weight: bold;' class='number-cell'>{value}</td>"
                                else:
                                    html_table += f"<td style='border: 1px solid #ddd; padding: 8px; text-align: right;' class='number-cell'>{value}</td>"
                            
                            html_table += "</tr>"
                        
                        html_table += "</table></div>"
                        st.markdown(html_table, unsafe_allow_html=True)
                    
                    else:
                        # N·∫øu l√† Series
                        html_table = "<div class='full-width-table'>"
                        html_table += "<table style='width:100%; border-collapse: collapse; font-size: 12px;'>"
                        html_table += "<tr style='background-color: #f0f2f6;'>"
                        html_table += "<th style='border: 1px solid #ddd; padding: 8px;'>Danh m·ª•c</th>"
                        html_table += "<th style='border: 1px solid #ddd; padding: 8px;'>Gi√° tr·ªã</th>"
                        html_table += "</tr>"
                        html_table += "<tr>"
                        html_table += f"<td style='border: 1px solid #ddd; padding: 8px;'>{category}</td>"
                        formatted_value = f"{category_data:,.0f}".replace(',', '.') if isinstance(category_data, (int, float, np.integer, np.floating)) else str(category_data)
                        html_table += f"<td style='border: 1px solid #ddd; padding: 8px; text-align: right;' class='number-cell'>{formatted_value}</td>"
                        html_table += "</tr>"
                        html_table += "</table></div>"
                        st.markdown(html_table, unsafe_allow_html=True)
            
            # PH·∫¶N 2: HI·ªÇN TH·ªä SPARKLINE CH·ªà CHO B√ÅO C√ÅO THEO TU·∫¶N
            # Ki·ªÉm tra n·∫øu pivot c√≥ c·ªôt l√† s·ªë tu·∫ßn (ho·∫∑c ƒë√£ ch·ªçn b√°o c√°o theo tu·∫ßn)
            if any(str(col).strip().isdigit() for col in pivot.columns if col != 'T·ªïng'):
                st.markdown("---")  # ƒê∆∞·ªùng ph√¢n c√°ch
                st.subheader("üìà Bi·ªÉu ƒë·ªì xu h∆∞·ªõng t·ªïng h·ª£p theo t·ª´ng n·ªôi dung")
                st.markdown("*Xu h∆∞·ªõng bi·∫øn ƒë·ªông qua c√°c tu·∫ßn cho m·ªói n·ªôi dung c√¥ng vi·ªác*")
                
                # T·∫°o container cho sparklines
                sparkline_data_all = {}
                
                # Thu th·∫≠p d·ªØ li·ªáu sparkline cho t·∫•t c·∫£ danh m·ª•c
                for category in sorted_categories:
                    try:
                        category_data = pivot.xs(category, level='Danh m·ª•c')
                        
                        if isinstance(category_data, pd.DataFrame):
                            # S·∫Øp x·∫øp theo th·ª© t·ª± ∆∞u ti√™n n·ªôi dung
                            contents = category_data.index.tolist()
                            sorted_contents = sorted(contents, key=lambda x: self.content_priority.get(x, 999))
                            category_data = category_data.reindex(sorted_contents)
                            
                            # L∆∞u v√†o dict chung
                            sparkline_data_all[category] = {
                                'data': category_data,
                                'contents': sorted_contents
                            }
                    except Exception as e:
                        continue
                
                # Hi·ªÉn th·ªã sparklines theo danh m·ª•c
                for category in sorted_categories:
                    if category in sparkline_data_all:
                        with st.expander(f"üìä Xu h∆∞·ªõng: {category}", expanded=False):
                            category_info = sparkline_data_all[category]
                            category_data = category_info['data']
                            
                            try:
                                # Header cho b·∫£ng sparkline
                                st.markdown("**üìä Xu h∆∞·ªõng bi·∫øn ƒë·ªông cho t·ª´ng n·ªôi dung:**")
                                
                                # T·∫°o b·∫£ng sparkline cho danh m·ª•c n√†y
                                sparkline_rows = []
                                
                                for content in category_info['contents']:
                                    # L·∫•y d·ªØ li·ªáu cho n·ªôi dung n√†y
                                    content_values = []
                                    for col in category_data.columns:
                                        if col != 'T·ªïng':  # B·ªè qua c·ªôt T·ªïng khi t√≠nh sparkline
                                            val = category_data.loc[content, col]
                                            if isinstance(val, str):
                                                # Extract s·ªë t·ª´ HTML
                                                import re
                                                numbers = re.findall(r'[\d.]+', val.replace('.', ''))
                                                if numbers:
                                                    content_values.append(int(numbers[0].replace('.', '')))
                                                else:
                                                    content_values.append(0)
                                            else:
                                                content_values.append(val if pd.notna(val) else 0)
                                    
                                    # T·∫°o sparkline
                                    fig = go.Figure()
                                    fig.add_trace(go.Scatter(
                                        y=content_values,
                                        mode='lines+markers',
                                        line=dict(width=2, color='royalblue'),
                                        marker=dict(size=3),
                                        showlegend=False
                                    ))
                                    
                                    # Highlight max/min
                                    if content_values and max(content_values) > 0:
                                        max_idx = np.argmax(content_values)
                                        min_idx = np.argmin(content_values)
                                        
                                        fig.add_trace(go.Scatter(
                                            x=[max_idx], y=[content_values[max_idx]],
                                            mode='markers', marker=dict(size=5, color='green'),
                                            showlegend=False
                                        ))
                                        fig.add_trace(go.Scatter(
                                            x=[min_idx], y=[content_values[min_idx]],
                                            mode='markers', marker=dict(size=5, color='red'),
                                            showlegend=False
                                        ))
                                    
                                    fig.update_layout(
                                        margin=dict(l=0, r=0, t=0, b=0),
                                        height=40, width=200,
                                        paper_bgcolor='rgba(0,0,0,0)',
                                        plot_bgcolor='rgba(0,0,0,0)',
                                        xaxis=dict(showticklabels=False, showgrid=False, zeroline=False),
                                        yaxis=dict(showticklabels=False, showgrid=False, zeroline=False),
                                        hovermode=False
                                    )
                                    
                                    # L·∫•y t·ªïng h√†ng t·ª´ c·ªôt T·ªïng
                                    row_total = category_data.loc[content, 'T·ªïng'] if 'T·ªïng' in category_data.columns else sum(content_values)
                                    
                                    # L∆∞u v√†o danh s√°ch
                                    sparkline_rows.append({
                                        'content': content,
                                        'fig': fig,
                                        'total': row_total,
                                        'values': content_values
                                    })
                                
                                # Hi·ªÉn th·ªã t·ª´ng row v·ªõi sparkline trong layout 3 c·ªôt
                                for row_data in sparkline_rows:
                                    col1, col2, col3 = st.columns([3, 2, 1])
                                    
                                    with col1:
                                        st.markdown(f"üìÑ {row_data['content']}")
                                    
                                    with col2:
                                        st.plotly_chart(row_data['fig'], use_container_width=True, 
                                                    key=f"spark_{category}_{row_data['content']}")
                                    
                                    with col3:
                                        if isinstance(row_data['total'], str):
                                            st.markdown(f"**{row_data['total']}**")
                                        else:
                                            st.markdown(f"**{row_data['total']:,.0f}**".replace(',', '.'))
                                
                                # Th·ªëng k√™ t·ªïng quan cho danh m·ª•c
                                total_category = sum([sum(row['values']) for row in sparkline_rows])
                                avg_per_content = total_category / len(sparkline_rows) if sparkline_rows else 0
                                
                                st.info(f"""
                                üìä **T·ªïng quan {category}:**
                                - üìà T·ªïng c·ªông: {total_category:,.0f}
                                - üìä Trung b√¨nh/n·ªôi dung: {avg_per_content:,.0f}
                                - üìã S·ªë n·ªôi dung: {len(sparkline_rows)}
                                """.replace(',', '.'))
                                        
                            except Exception as e:
                                st.error(f"L·ªói t·∫°o sparkline cho {category}: {str(e)}")
        
        elif 'Danh m·ª•c' in pivot.index.names:
            # Hi·ªÉn th·ªã ƒë∆°n gi·∫£n v·ªõi Danh m·ª•c
            categories = pivot.index.unique()
            sorted_categories = sorted(categories, key=lambda x: self.category_priority.get(x, 999))
            
            for category in sorted_categories:
                with st.expander(f"üìÅ {category}", expanded=True):
                    category_data = pivot.loc[category]
                    
                    html_table = "<table style='width:100%; border-collapse: collapse;'>"
                    html_table += "<tr style='background-color: #f0f2f6;'>"
                    html_table += "<th style='border: 1px solid #ddd; padding: 8px;'>Danh m·ª•c</th>"
                    html_table += "<th style='border: 1px solid #ddd; padding: 8px;'>Gi√° tr·ªã</th>"
                    html_table += "</tr>"
                    html_table += "<tr>"
                    html_table += f"<td style='border: 1px solid #ddd; padding: 8px;'>{category}</td>"
                    html_table += f"<td style='border: 1px solid #ddd; padding: 8px; text-align: right;' class='number-cell'>{category_data}</td>"
                    html_table += "</tr>"
                    html_table += "</table>"
                    st.markdown(html_table, unsafe_allow_html=True)
        
        else:
            # Hi·ªÉn th·ªã pivot table th√¥ng th∆∞·ªùng
            st.subheader("üìä Pivot Table")
            
            html_table = "<div class='full-width-table'>"
            html_table += "<table style='width:100%; border-collapse: collapse; font-size: 12px;'>"
            
            # Header
            html_table += "<tr style='background-color: #f0f2f6;'>"
            html_table += "<th style='border: 1px solid #ddd; padding: 8px;'>Index</th>"
            if isinstance(pivot, pd.DataFrame):
                for col in pivot.columns:
                    html_table += f"<th style='border: 1px solid #ddd; padding: 8px; text-align: center;'>{col}</th>"
            else:
                html_table += "<th style='border: 1px solid #ddd; padding: 8px; text-align: center;'>Gi√° tr·ªã</th>"
            html_table += "</tr>"
            
            # Data
            if isinstance(pivot, pd.DataFrame):
                for idx in pivot.index:
                    html_table += "<tr>"
                    html_table += f"<td style='border: 1px solid #ddd; padding: 8px;'>{idx}</td>"
                    for col in pivot.columns:
                        value = pivot.loc[idx, col]
                        html_table += f"<td style='border: 1px solid #ddd; padding: 8px; text-align: right;' class='number-cell'>{value}</td>"
                    html_table += "</tr>"
            else:
                for idx in pivot.index:
                    html_table += "<tr>"
                    html_table += f"<td style='border: 1px solid #ddd; padding: 8px;'>{idx}</td>"
                    html_table += f"<td style='border: 1px solid #ddd; padding: 8px; text-align: right;' class='number-cell'>{pivot.loc[idx]}</td>"
                    html_table += "</tr>"
            
            html_table += "</table></div>"
            st.markdown(html_table, unsafe_allow_html=True)
    
    def create_sparkline_charts(self, pivot, report_type):
        """T·∫°o bi·ªÉu ƒë·ªì sparkline cho m·ªói d√≤ng trong pivot table"""
        if pivot is None or not isinstance(pivot, pd.DataFrame):
            return None
        
        # X√°c ƒë·ªãnh c·ªôt th·ªùi gian d·ª±a v√†o report_type
        time_column_name = {
            "Theo Tu·∫ßn": "Tu·∫ßn",
            "Theo Th√°ng": "Th√°ng",
            "Theo Qu√Ω": "Qu√Ω",
            "Theo NƒÉm": "NƒÉm"
        }.get(report_type, "Th√°ng")
        
        # T·∫°o dataframe cho bi·ªÉu ƒë·ªì
        sparklines_data = {}
        
        # Reset index ƒë·ªÉ d·ªÖ d√†ng x·ª≠ l√Ω
        if isinstance(pivot.index, pd.MultiIndex):
            pivot_reset = pivot.reset_index()
        else:
            pivot_reset = pivot.reset_index()
            
        # L·∫•y t√™n c·ªßa c√°c c·ªôt ch·ª©a gi√° tr·ªã
        value_columns = [col for col in pivot.columns 
                         if not isinstance(col, tuple) or time_column_name in col]
        
        # T·∫°o sparkline cho m·ªói d√≤ng
        for idx, row in pivot_reset.iterrows():
                
            # L·∫•y t√™n h√†ng
            if isinstance(pivot.index, pd.MultiIndex):
                row_key = tuple(row[list(pivot.index.names)])
            else:
                row_key = row[pivot.index.name]
                
            # L·∫•y gi√° tr·ªã cho sparkline (extract t·ª´ HTML n·∫øu c·∫ßn)
            values = []
            for col in value_columns:
                try:
                    if col in pivot.columns:
                        val = pivot.loc[row_key, col]
                        # N·∫øu l√† chu·ªói HTML, l·∫•y s·ªë ƒë·∫ßu ti√™n
                        if isinstance(val, str):
                            import re
                            numbers = re.findall(r'[\d.]+', val.replace('.', ''))
                            if numbers:
                                values.append(int(numbers[0].replace('.', '')))
                            else:
                                values.append(0)
                        else:
                            values.append(val)
                except:
                    values.append(0)
            
            # T·∫°o sparkline figure
            fig = go.Figure()
            
            # Th√™m line chart
            fig.add_trace(go.Scatter(
                y=values,
                mode='lines+markers',
                line=dict(width=2, color='royalblue'),
                marker=dict(size=4),
                showlegend=False
            ))
            
            # Highlight ƒëi·ªÉm cao nh·∫•t
            if values:
                max_idx = np.argmax(values)
                fig.add_trace(go.Scatter(
                    x=[max_idx],
                    y=[values[max_idx]],
                    mode='markers',
                    marker=dict(size=6, color='green'),
                    showlegend=False
                ))
                
                # Highlight ƒëi·ªÉm th·∫•p nh·∫•t
                min_idx = np.argmin(values)
                fig.add_trace(go.Scatter(
                    x=[min_idx],
                    y=[values[min_idx]],
                    mode='markers',
                    marker=dict(size=6, color='red'),
                    showlegend=False
                ))
            
            # ƒê·ªãnh d·∫°ng figure
            fig.update_layout(
                margin=dict(l=0, r=0, t=0, b=0),
                height=30,
                width=150,
                paper_bgcolor='rgba(0,0,0,0)',
                plot_bgcolor='rgba(0,0,0,0)',
                xaxis=dict(
                    showticklabels=False,
                    showgrid=False,
                    zeroline=False
                ),
                yaxis=dict(
                    showticklabels=False,
                    showgrid=False,
                    zeroline=False
                ),
                hovermode=False
            )
            
            # L∆∞u figure
            sparklines_data[row_key] = fig
            
        return sparklines_data
    
    def create_individual_trend_chart(self, data, content_item, time_col, chart_type="ƒê∆∞·ªùng", normalize=False):
        """T·∫°o bi·ªÉu ƒë·ªì xu h∆∞·ªõng ri√™ng cho m·ªôt n·ªôi dung c·ª• th·ªÉ"""
        try:
            # L·ªçc d·ªØ li·ªáu cho n·ªôi dung ƒë∆∞·ª£c ch·ªçn
            content_data = data[data['N·ªôi dung'] == content_item]
            
            if content_data.empty:
                return None
                
            # T·∫°o pivot table cho n·ªôi dung n√†y
            pivot_data = pd.pivot_table(
                content_data,
                index='N·ªôi dung',
                columns=time_col,
                values='S·ªë li·ªáu',
                aggfunc='sum',
                fill_value=0
            )
            
            # L·∫•y gi√° tr·ªã cho bi·ªÉu ƒë·ªì
            time_values = list(pivot_data.columns)
            data_values = pivot_data.iloc[0].values
            
            # Chu·∫©n h√≥a d·ªØ li·ªáu n·∫øu c·∫ßn
            if normalize and max(data_values) > 0:
                data_values = data_values / max(data_values) * 100
            
            # B·ªé HI·ªÇN TH·ªä S·ªê ∆ØU TI√äN
            title = f"{content_item}"
            
            # T·∫°o bi·ªÉu ƒë·ªì t∆∞∆°ng ·ª©ng v·ªõi lo·∫°i ƒë√£ ch·ªçn
            if chart_type == "ƒê∆∞·ªùng":
                fig = px.line(
                    x=time_values,
                    y=data_values,
                    markers=True,
                    title=title
                )
                
                # Th√™m ƒëi·ªÉm cao nh·∫•t v√† th·∫•p nh·∫•t
                if len(data_values) > 0:
                    max_idx = np.argmax(data_values)
                    fig.add_trace(go.Scatter(
                        x=[time_values[max_idx]],
                        y=[data_values[max_idx]],
                        mode='markers',
                        marker=dict(size=10, color='green', symbol='circle'),
                        name='Cao nh·∫•t',
                        showlegend=False
                    ))
                    
                    min_idx = np.argmin(data_values)
                    fig.add_trace(go.Scatter(
                        x=[time_values[min_idx]],
                        y=[data_values[min_idx]],
                        mode='markers',
                        marker=dict(size=10, color='red', symbol='circle'),
                        name='Th·∫•p nh·∫•t',
                        showlegend=False
                    ))
                
            elif chart_type == "C·ªôt":
                fig = px.bar(
                    x=time_values,
                    y=data_values,
                    title=title
                )
                
                # Highlight c·ªôt cao nh·∫•t v√† th·∫•p nh·∫•t
                if len(data_values) > 0:
                    max_idx = np.argmax(data_values)
                    min_idx = np.argmin(data_values)
                    
                    bar_colors = ['royalblue'] * len(data_values)
                    bar_colors[max_idx] = 'green'
                    bar_colors[min_idx] = 'red'
                    
                    fig.update_traces(marker_color=bar_colors)
                
            else:  # V√πng
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=time_values,
                    y=data_values,
                    mode='lines',
                    fill='tozeroy',
                    line=dict(color='royalblue'),
                    name=content_item
                ))
                
                # Th√™m ƒëi·ªÉm cao nh·∫•t v√† th·∫•p nh·∫•t
                if len(data_values) > 0:
                    max_idx = np.argmax(data_values)
                    fig.add_trace(go.Scatter(
                        x=[time_values[max_idx]],
                        y=[data_values[max_idx]],
                        mode='markers',
                        marker=dict(size=10, color='green', symbol='circle'),
                        name='Cao nh·∫•t',
                        showlegend=False
                    ))
                    
                    min_idx = np.argmin(data_values)
                    fig.add_trace(go.Scatter(
                        x=[time_values[min_idx]],
                        y=[data_values[min_idx]],
                        mode='markers',
                        marker=dict(size=10, color='red', symbol='circle'),
                        name='Th·∫•p nh·∫•t',
                        showlegend=False
                    ))
                
                fig.update_layout(title=title)
            
            # C·∫≠p nh·∫≠t layout
            y_title = "% (so v·ªõi gi√° tr·ªã cao nh·∫•t)" if normalize else "Gi√° tr·ªã"
            time_col_display = {"Tu·∫ßn": "Tu·∫ßn", "Th√°ng": "Th√°ng", "Qu√Ω": "Qu√Ω", "NƒÉm": "NƒÉm"}.get(time_col, time_col)
            
            fig.update_layout(
                xaxis_title=time_col_display,
                yaxis_title=y_title,
                height=300,
                margin=dict(l=10, r=10, t=40, b=40),
                hovermode="x",
                plot_bgcolor='rgba(240,240,240,0.1)'
            )
            
            # Th√™m ƒë∆∞·ªùng xu h∆∞·ªõng n·∫øu c√≥ ƒë·ªß d·ªØ li·ªáu
            if len(data_values) > 2:
                x_values = list(range(len(data_values)))
                coeffs = np.polyfit(x_values, data_values, 1)
                trend_line = np.poly1d(coeffs)(x_values)
                
                # X√°c ƒë·ªãnh m√†u ƒë∆∞·ªùng xu h∆∞·ªõng
                trend_color = 'green' if coeffs[0] > 0 else 'red'
                
                if chart_type in ["ƒê∆∞·ªùng", "V√πng"]:
                    fig.add_trace(go.Scatter(
                        x=time_values,
                        y=trend_line,
                        mode='lines',
                        line=dict(color=trend_color, dash='dash', width=2),
                        name='Xu h∆∞·ªõng',
                        showlegend=False
                    ))
            
            return fig
            
        except Exception as e:
            st.error(f"L·ªói khi t·∫°o bi·ªÉu ƒë·ªì cho {content_item}: {str(e)}")
            return None

def main():
    if 'authenticated' in st.session_state and st.session_state.authenticated:
        # ƒê√£ ƒëƒÉng nh·∫≠p ·ªü main dashboard - bypass login ho√†n to√†n
        pass
    else:
        # Ch∆∞a ƒëƒÉng nh·∫≠p - redirect v·ªÅ main dashboard
        st.error("üîí B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ truy c·∫≠p dashboard n√†y!")
        st.info("üëÜ Vui l√≤ng quay l·∫°i trang ch√≠nh ƒë·ªÉ ƒëƒÉng nh·∫≠p.")
        
        if st.button("üè† Quay l·∫°i trang ch√≠nh", use_container_width=True):
            st.query_params.clear()
            st.switch_page("main_dashboard.py")  # Ho·∫∑c redirect v·ªÅ main
        return
        
    # HEADER: logo + title on one line (flexbox)
    try:
        # Encode logo to base64 for inline <img>
        script_dir = os.path.dirname(os.path.abspath(__file__))
        logo_path = os.path.join(script_dir, "assets", "logo.png")
        logo_base64 = ""
        if os.path.exists(logo_path):
            with open(logo_path, "rb") as f:
                logo_base64 = base64.b64encode(f.read()).decode()
    except Exception:
        logo_base64 = ""

    # Hi·ªÉn th·ªã logo trong sidebar
    if logo_base64:
        st.sidebar.image(f"data:image/png;base64,{logo_base64}", width=100)

    header_html = f"""
    <div style='
        display:flex;
        align-items:center;
        justify-content:center;
        padding:10px 0;
        background:#ffffff;
        border-radius:15px;
        margin-bottom:0;
    '>
        <h1 style='
            color:#1f77b4;
            margin:0;
            font-size:2.7rem;
            font-weight:bold;
            font-family:"Segoe UI", Arial, sans-serif;
            text-shadow:2px 2px 4px rgba(0,0,0,0.1);
            letter-spacing:1px; text-align:center;'>
            Dashboard ho·∫°t ƒë·ªông Ph√≤ng H√†nh ch√≠nh
        </h1>
    </div>
    """
    st.markdown(header_html, unsafe_allow_html=True)
    
    # Footer g·ªçn g√†ng ‚Äì gom to√†n b·ªô th√¥ng tin d·ª± √°n v√†o m·ªôt expander cu·ªëi trang
    st.markdown("---")
    with st.expander("‚ÑπÔ∏è Th√¥ng tin v·ªÅ Dashboard", expanded=False):
        # Gi·ªõi thi·ªáu v√† t√≠nh nƒÉng
        st.markdown("""
        **üè• Dashboard chuy√™n bi·ªát cho Ph√≤ng H√†nh Ch√≠nh B·ªánh vi·ªán**

        **‚ú® T√≠nh nƒÉng n·ªïi b·∫≠t:**
        - üìã 13 danh m·ª•c v√† 70+ n·ªôi dung theo th·ª© t·ª± ∆∞u ti√™n c·ªë ƒë·ªãnh  
        - üìà Hi·ªÉn th·ªã bi·∫øn ƒë·ªông tu·∫ßn (%) ngay trong gi√° tr·ªã: `1.234.567 (‚Üë15%)`  
        - üîí C·ªôt **N·ªôi dung** v√† **T·ªïng** ƒë√≥ng bƒÉng khi cu·ªôn  
        - üìä Sparkline xu h∆∞·ªõng cho t·ª´ng danh m·ª•c  
        - üíæ Xu·∫•t b√°o c√°o Excel ƒëa sheet v√† CSV  
        - ‚òÅÔ∏è T·ª± ƒë·ªông sync v·ªõi GitHub storage  
        """)
        # Th√¥ng tin b·∫£n quy·ªÅn + GitHub
        st.markdown("""
        <div style='text-align: center; color: #666; padding: 15px; background-color:rgba(255, 255, 255, 0.08);
                    border-radius: 10px; margin-top: 20px;'>
            <p style='margin: 0; font-size: 14px;'>
                üè• <strong>Ph√≤ng H√†nh Ch√≠nh - B·ªánh vi·ªán ƒê·∫°i h·ªçc Y D∆∞·ª£c TPHCM - University Medical Center HCMC (UMC)</strong>
                &nbsp;|&nbsp;
                üåê <a href="https://github.com/corner-25/dashboard-phong-hanh-chinh" target="_blank"
                      style="text-decoration: none; color: #1f77b4;">GitHub Project</a>
            </p>
            <p style='margin: 5px 0 0 0; font-size: 12px; color: #888;'>
                ¬© 2025 Dashboard Ph√≤ng H√†nh Ch√≠nh ‚Äî Ph√°t tri·ªÉn b·ªüi <strong>D∆∞∆°ng H·ªØu Quang</strong>
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    # Kh·ªüi t·∫°o dashboard v√† DataManager
    dashboard = PivotTableDashboard()
    
    # Initialize data manager ƒë·ªÉ load d·ªØ li·ªáu t·ª´ GitHub
    if 'data_manager' not in st.session_state:
        st.session_state.data_manager = DataManager()
    
    manager = st.session_state.data_manager
    
    # Ki·ªÉm tra k·∫øt n·ªëi GitHub
    connected, status_msg = manager.check_github_connection()
    
    file_loaded = False
    
    if connected:
        st.sidebar.success("‚òÅÔ∏è K·∫øt n·ªëi GitHub th√†nh c√¥ng")
        
        # Th·ª≠ load d·ªØ li·ªáu t·ª´ GitHub tr∆∞·ªõc
        try:
            github_data, metadata = manager.load_current_data()
            
            if github_data is not None and metadata:
                # C√≥ d·ªØ li·ªáu t·ª´ GitHub
                st.sidebar.info(f"""
                üìä **D·ªØ li·ªáu t·ª´ GitHub:**
                - üìÑ {metadata.get('filename', 'Unknown')}
                - üìÖ Tu·∫ßn {metadata.get('week_number', '?')}/{metadata.get('year', '?')}
                """)
                
                # Load v√†o dashboard - S·ª¨A L·∫†I D√íNG N√ÄY
                if dashboard.load_data_from_dataframe(github_data):
                    file_loaded = True
                else:
                    st.sidebar.warning("‚ö†Ô∏è L·ªói x·ª≠ l√Ω d·ªØ li·ªáu GitHub")
                    file_loaded = False
            else:
                st.sidebar.warning("üì≠ Ch∆∞a c√≥ d·ªØ li·ªáu tr√™n GitHub")
                file_loaded = False
                
        except Exception as github_error:
            st.sidebar.error(f"‚ùå L·ªói load GitHub: {str(github_error)}")
            file_loaded = False
    else:
        st.sidebar.warning("‚ö†Ô∏è Kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c GitHub")
        file_loaded = False
    
    # Upload section trong sidebar
    st.sidebar.header("üì§ Upload d·ªØ li·ªáu m·ªõi")
    
    # Ch·ªçn c√°ch nh·∫≠p d·ªØ li·ªáu
    data_source = st.sidebar.radio(
        "Ch·ªçn ngu·ªìn d·ªØ li·ªáu",
        ["Upload file", "Nh·∫≠p ƒë∆∞·ªùng d·∫´n file"]
    )
    
    if data_source == "Upload file":
        uploaded_file = st.sidebar.file_uploader("Ch·ªçn file Excel", type=['xlsx', 'xls'])
        if uploaded_file is not None:
            # N·∫øu c√≥ GitHub connection, cho ph√©p upload l√™n GitHub
            if connected:
                col1, col2 = st.sidebar.columns(2)
                with col1:
                    if st.button("üìä Xem tr∆∞·ªõc", use_container_width=True):
                        if dashboard.load_data(uploaded_file):
                            st.sidebar.success("‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu th√†nh c√¥ng!")
                            file_loaded = True
                
                with col2:
                    if st.button("‚òÅÔ∏è Upload GitHub", use_container_width=True):
                        # ƒê·ªçc file ƒë·ªÉ upload
                        try:
                            data = pd.read_excel(uploaded_file)
                            success = manager.upload_new_file(data, uploaded_file.name)
                            if success:
                                st.balloons()
                                time.sleep(1)
                                st.rerun()
                        except Exception as e:
                            st.sidebar.error(f"‚ùå L·ªói upload: {str(e)}")
            else:
                # Kh√¥ng c√≥ GitHub, ch·ªâ xem local
                if dashboard.load_data(uploaded_file):
                    st.sidebar.success("‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu th√†nh c√¥ng!")
                    file_loaded = True
        
        # T·ª± ƒë·ªông load l·∫°i n·∫øu ƒë√£ c√≥ ƒë∆∞·ªùng d·∫´n trong session
        if 'file_path' in st.session_state:
            if os.path.exists(st.session_state['file_path']):
                dashboard.load_data(st.session_state['file_path'])
                file_loaded = True
    
    # Ph·∫ßn c√≤n l·∫°i c·ªßa dashboard (ch·ªâ hi·ªÉn th·ªã khi c√≥ d·ªØ li·ªáu)
    if file_loaded and dashboard.data is not None:
        # T·∫°o c√°c c√†i ƒë·∫∑t v√† b·ªô l·ªçc
        report_type, rows, cols, values, agg_func, show_ratio_inline = dashboard.create_pivot_settings()
        from_year, from_month, from_week, to_year, to_month, to_week, categories = dashboard.create_filters()
        
        # √Åp d·ª•ng b·ªô l·ªçc
        filtered_data = dashboard.filter_data(from_year, from_month, from_week, to_year, to_month, to_week, categories)
        
        # TH√äM: T·ª± ƒë·ªông aggregate theo lo·∫°i b√°o c√°o
        aggregated_data = dashboard.aggregate_data_by_report_type(filtered_data, report_type)
        
        # N√∫t l√†m m·ªõi d·ªØ li·ªáu
        if st.sidebar.button("üîÑ L√†m m·ªõi d·ªØ li·ªáu", use_container_width=True):
            if connected:
                # Reload t·ª´ GitHub
                try:
                    github_data, metadata = manager.load_current_data()
                    if github_data is not None:
                        dashboard.load_data_from_dataframe(github_data)
                        st.rerun()
                except:
                    pass
            elif 'file_path' in st.session_state:
                dashboard.load_data(st.session_state['file_path'])
                st.rerun()
        
        # Tabs cho c√°c ch·∫ø ƒë·ªô xem
        tab1, tab2, tab3 = st.tabs(["üìã Pivot Table", "üìä Xu h∆∞·ªõng theo th·ªùi gian", "üíæ Xu·∫•t b√°o c√°o"])
        
        with tab1:
            # T·∫°o pivot table v·ªõi bi·∫øn ƒë·ªông - S·ª¨ D·ª§NG aggregated_data
            pivot = dashboard.create_hierarchical_pivot_table_with_ratio(
                aggregated_data, rows, cols, values, agg_func, show_ratio_inline
            )
            
            if pivot is not None:
                # Hi·ªÉn th·ªã pivot table c·∫£i ti·∫øn
                dashboard.display_hierarchical_pivot_improved(pivot, aggregated_data)
                
                # T√πy ch·ªçn xu·∫•t
                col1, col2 = st.columns(2)
                with col1:
                    # T·∫°o CSV t·ª´ d·ªØ li·ªáu g·ªëc (kh√¥ng c√≥ HTML)
                    if show_ratio_inline and report_type == "Theo Tu·∫ßn":
                        st.info("üí° Xu·∫•t CSV s·∫Ω ch·ª©a d·ªØ li·ªáu g·ªëc (kh√¥ng c√≥ bi·∫øn ƒë·ªông HTML)")
                    
                    # T·∫°o pivot ƒë∆°n gi·∫£n cho CSV
                    simple_pivot = pd.pivot_table(
                        aggregated_data,
                        index=rows if rows else None,
                        columns=cols if cols else None,
                        values=values,
                        aggfunc=agg_func,
                        fill_value=0,
                        margins=False  # B·ªé T·ªîNG CHUNG
                    )
                    
                    csv = simple_pivot.to_csv(encoding='utf-8-sig')
                    st.download_button(
                        "üì• T·∫£i CSV",
                        csv,
                        f"pivot_table_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        "text/csv"
                    )
        
        with tab2:
            st.header("Xu h∆∞·ªõng theo th·ªùi gian (theo th·ª© t·ª± ∆∞u ti√™n)")
            
            # X√°c ƒë·ªãnh tr∆∞·ªùng th·ªùi gian d·ª±a v√†o ki·ªÉu b√°o c√°o
            time_col = {
                "Theo Tu·∫ßn": "Tu·∫ßn", 
                "Theo Th√°ng": "Th√°ng", 
                "Theo Qu√Ω": "Qu√Ω", 
                "Theo NƒÉm": "NƒÉm"
            }.get(report_type, "Th√°ng")
            
            # Hi·ªÉn th·ªã t√πy ch·ªçn cho bi·ªÉu ƒë·ªì
            col1, col2, col3 = st.columns(3)
            
            with col1:
                chart_type = st.selectbox(
                    "Lo·∫°i bi·ªÉu ƒë·ªì",
                    ["ƒê∆∞·ªùng", "C·ªôt", "V√πng"]
                )
            
            with col2:
                normalize = st.checkbox("Chu·∫©n h√≥a (so s√°nh %)", value=False)
                
            with col3:
                num_cols = st.select_slider(
                    "S·ªë c·ªôt hi·ªÉn th·ªã",
                    options=[1, 2, 3],
                    value=2
                )
            
            # L·ªçc d·ªØ li·ªáu cho c√°c N·ªôi dung (hi·ªÉn th·ªã theo th·ª© t·ª± ∆∞u ti√™n) - S·ª¨ D·ª§NG aggregated_data
            unique_contents = aggregated_data['N·ªôi dung'].unique()
            sorted_contents = sorted(unique_contents, key=lambda x: dashboard.content_priority.get(x, 999))
            
            content_filter = st.multiselect(
                "Ch·ªçn N·ªôi dung c·∫ßn hi·ªÉn th·ªã (theo th·ª© t·ª± ∆∞u ti√™n)",
                sorted_contents,
                default=sorted_contents[:10]  # M·∫∑c ƒë·ªãnh hi·ªÉn th·ªã 10 n·ªôi dung ƒë·∫ßu ti√™n
            )
            
            filtered_for_charts = aggregated_data[aggregated_data['N·ªôi dung'].isin(content_filter)]
            
            if filtered_for_charts.empty:
                st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc ƒë√£ ch·ªçn!")
            else:
                # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì cho t·ª´ng n·ªôi dung ri√™ng bi·ªát
                st.subheader(f"Bi·ªÉu ƒë·ªì xu h∆∞·ªõng theo {time_col} cho t·ª´ng N·ªôi dung")
                
                # S·∫Øp x·∫øp d·ªØ li·ªáu theo th·ª© t·ª± ∆∞u ti√™n
                sorted_data = filtered_for_charts.copy()
                sorted_data = sorted_data.sort_values(['Danh_m·ª•c_th·ª©_t·ª±', 'N·ªôi_dung_th·ª©_t·ª±'])
                
                # T·∫°o container cho c√°c danh m·ª•c
                categories = sorted_data['Danh m·ª•c'].unique()
                sorted_categories = sorted(categories, key=lambda x: dashboard.category_priority.get(x, 999))
                
                for category in sorted_categories:
                    # Hi·ªÉn th·ªã Danh m·ª•c v·ªõi expander (B·ªé HI·ªÇN TH·ªä S·ªê ∆ØU TI√äN)
                    with st.expander(f"üìÅ {category}", expanded=True):
                        # L·ªçc d·ªØ li·ªáu cho danh m·ª•c n√†y
                        category_data = sorted_data[sorted_data['Danh m·ª•c'] == category]
                        
                        # L·∫•y danh s√°ch n·ªôi dung trong danh m·ª•c (ƒë√£ s·∫Øp x·∫øp)
                        category_contents = category_data['N·ªôi dung'].unique()
                        sorted_category_contents = sorted(category_contents, 
                                                        key=lambda x: dashboard.content_priority.get(x, 999))
                        
                        # T·∫°o grid hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
                        cols_container = st.columns(num_cols)
                        
                        # Duy·ªát qua t·ª´ng n·ªôi dung v√† t·∫°o bi·ªÉu ƒë·ªì ri√™ng
                        for i, content_item in enumerate(sorted_category_contents):
                            # T·∫°o bi·ªÉu ƒë·ªì cho n·ªôi dung n√†y
                            fig = dashboard.create_individual_trend_chart(
                                category_data, content_item, time_col, chart_type, normalize
                            )
                            
                            if fig is not None:
                                # Hi·ªÉn th·ªã trong c·ªôt t∆∞∆°ng ·ª©ng
                                col_idx = i % num_cols
                                with cols_container[col_idx]:
                                    st.plotly_chart(fig, use_container_width=True)
                
                # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu
                with st.expander("Xem d·ªØ li·ªáu chi ti·∫øt (theo th·ª© t·ª± ∆∞u ti√™n)"):
                    # T·∫°o pivot cho xem d·ªØ li·ªáu chi ti·∫øt - S·ª¨ D·ª§NG aggregated_data
                    detail_pivot = pd.pivot_table(
                        filtered_for_charts,
                        index=['Danh m·ª•c', 'N·ªôi dung'],
                        columns=time_col,
                        values='S·ªë li·ªáu',
                        aggfunc='sum',
                        fill_value=0
                    )
                    
                    # S·∫Øp x·∫øp theo th·ª© t·ª± ∆∞u ti√™n
                    detail_pivot_sorted = detail_pivot.copy()
                    detail_pivot_sorted['Danh_m·ª•c_th·ª©_t·ª±'] = detail_pivot_sorted.index.get_level_values('Danh m·ª•c').map(dashboard.category_priority).fillna(999)
                    detail_pivot_sorted['N·ªôi_dung_th·ª©_t·ª±'] = detail_pivot_sorted.index.get_level_values('N·ªôi dung').map(dashboard.content_priority).fillna(999)
                    detail_pivot_sorted = detail_pivot_sorted.sort_values(['Danh_m·ª•c_th·ª©_t·ª±', 'N·ªôi_dung_th·ª©_t·ª±'])
                    detail_pivot_sorted = detail_pivot_sorted.drop(columns=['Danh_m·ª•c_th·ª©_t·ª±', 'N·ªôi_dung_th·ª©_t·ª±'])
                    
                    # Hi·ªÉn th·ªã v·ªõi HTML table ƒë·ªÉ ƒë·∫£m b·∫£o hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß s·ªë
                    html_table = "<div class='full-width-table'>"
                    html_table += "<table style='width:100%; border-collapse: collapse; font-size: 11px;'>"
                    html_table += "<tr style='background-color: #f0f2f6;'>"
                    html_table += "<th style='border: 1px solid #ddd; padding: 6px;'>Danh m·ª•c</th>"
                    html_table += "<th style='border: 1px solid #ddd; padding: 6px;'>N·ªôi dung</th>"
                    for col in detail_pivot_sorted.columns:
                        html_table += f"<th style='border: 1px solid #ddd; padding: 6px; text-align: center;'>{col}</th>"
                    html_table += "</tr>"
                    
                    for idx in detail_pivot_sorted.index:
                        html_table += "<tr>"
                        html_table += f"<td style='border: 1px solid #ddd; padding: 6px;'>{idx[0]}</td>"
                        html_table += f"<td style='border: 1px solid #ddd; padding: 6px;'>{idx[1]}</td>"
                        for col in detail_pivot_sorted.columns:
                            value = detail_pivot_sorted.loc[idx, col]
                            formatted_value = f"{value:,.0f}".replace(',', '.')
                            html_table += f"<td style='border: 1px solid #ddd; padding: 6px; text-align: right;' class='number-cell'>{formatted_value}</td>"
                        html_table += "</tr>"
                    
                    html_table += "</table></div>"
                    st.markdown(html_table, unsafe_allow_html=True)
        
        with tab3:
            st.header("Xu·∫•t b√°o c√°o")
            
            # T·∫°o b√°o c√°o t·ªïng h·ª£p
            report_format = st.selectbox(
                "Ch·ªçn ƒë·ªãnh d·∫°ng",
                ["Excel ƒëa sheet v·ªõi th·ª© t·ª± ∆∞u ti√™n", "Excel ƒë∆°n gi·∫£n", "CSV"]
            )
            
            if st.button("T·∫°o b√°o c√°o", use_container_width=True):
                if report_format == "Excel ƒëa sheet v·ªõi th·ª© t·ª± ∆∞u ti√™n":
                    # T·∫°o file Excel v·ªõi nhi·ªÅu sheet
                    output_file = f'bao_cao_phong_hanh_chinh_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx'
                    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:
                        # Sheet 1: D·ªØ li·ªáu g·ªëc (ƒë√£ s·∫Øp x·∫øp) - S·ª¨ D·ª§NG aggregated_data
                        aggregated_data_export = aggregated_data.drop(columns=['Danh_m·ª•c_th·ª©_t·ª±', 'N·ªôi_dung_th·ª©_t·ª±'], errors='ignore')
                        aggregated_data_export.to_excel(writer, sheet_name='D·ªØ li·ªáu ƒë√£ aggregate', index=False)
                        
                        # Sheet 2: Pivot table (d·ªØ li·ªáu s·ªë, kh√¥ng c√≥ HTML) - S·ª¨ D·ª§NG aggregated_data
                        simple_pivot = pd.pivot_table(
                            aggregated_data,
                            index=rows if rows else None,
                            columns=cols if cols else None,
                            values=values,
                            aggfunc=agg_func,
                            fill_value=0,
                            margins=False  # B·ªé T·ªîNG CHUNG
                        )
                        simple_pivot.to_excel(writer, sheet_name='Pivot Table')
                        
                        # Sheet 3: T·ªïng h·ª£p theo danh m·ª•c (theo th·ª© t·ª± ∆∞u ti√™n) - S·ª¨ D·ª§NG aggregated_data
                        category_summary = aggregated_data.groupby('Danh m·ª•c')['S·ªë li·ªáu'].agg(['sum', 'mean', 'count'])
                        category_summary['Th·ª©_t·ª±'] = category_summary.index.map(dashboard.category_priority).fillna(999)
                        category_summary = category_summary.sort_values('Th·ª©_t·ª±').drop(columns=['Th·ª©_t·ª±'])
                        category_summary.to_excel(writer, sheet_name='Theo danh m·ª•c')
                        
                        # Sheet 4: T·ªïng h·ª£p theo th·ªùi gian - S·ª¨ D·ª§NG aggregated_data
                        time_summary = aggregated_data.pivot_table(
                            index=time_col,
                            columns='Danh m·ª•c',
                            values='S·ªë li·ªáu',
                            aggfunc='sum',
                            fill_value=0
                        )
                        time_summary.to_excel(writer, sheet_name='Theo th·ªùi gian')
                        
                        # Sheet 5: T·ªïng h·ª£p theo n·ªôi dung (theo th·ª© t·ª± ∆∞u ti√™n) - S·ª¨ D·ª§NG aggregated_data
                        content_summary = aggregated_data.pivot_table(
                            index=['Danh m·ª•c', 'N·ªôi dung'],
                            values='S·ªë li·ªáu',
                            aggfunc=['sum', 'mean', 'count'],
                            fill_value=0
                        )
                        content_summary.to_excel(writer, sheet_name='Theo n·ªôi dung')
                        
                        # Sheet 6: T·ª∑ l·ªá thay ƒë·ªïi - CH·ªà CHO B√ÅO C√ÅO THEO TU·∫¶N
                        if report_type == "Theo Tu·∫ßn":
                            ratio_data = aggregated_data[aggregated_data['T·ª∑_l·ªá_tu·∫ßn_tr∆∞·ªõc'] != 0]
                            if not ratio_data.empty:
                                ratio_summary = ratio_data.pivot_table(
                                    index=['Danh m·ª•c', 'N·ªôi dung'],
                                    columns='Tu·∫ßn',
                                    values=['T·ª∑_l·ªá_tu·∫ßn_tr∆∞·ªõc', 'Thay_ƒë·ªïi_tu·∫ßn_tr∆∞·ªõc'],
                                    aggfunc='mean',
                                    fill_value=None
                                )
                                ratio_summary.to_excel(writer, sheet_name='T·ª∑ l·ªá thay ƒë·ªïi')
                        
                        # Sheet 7: C·∫•u h√¨nh th·ª© t·ª± ∆∞u ti√™n c·ªë ƒë·ªãnh
                        priority_df = pd.DataFrame([
                            {'Lo·∫°i': 'Danh m·ª•c', 'T√™n': k, 'Th·ª© t·ª±': v} 
                            for k, v in dashboard.category_priority.items()
                        ] + [
                            {'Lo·∫°i': 'N·ªôi dung', 'T√™n': k, 'Th·ª© t·ª±': v} 
                            for k, v in dashboard.content_priority.items()
                        ])
                
                        priority_df = priority_df.sort_values(['Lo·∫°i', 'Th·ª© t·ª±'])
                        priority_df.to_excel(writer, sheet_name='Th·ª© t·ª± ∆∞u ti√™n', index=False)
                    
                    with open(output_file, 'rb') as f:
                        st.download_button(
                            "üì• T·∫£i b√°o c√°o Excel v·ªõi th·ª© t·ª± ∆∞u ti√™n",
                            f.read(),
                            output_file,
                            "application/vnd.ms-excel"
                        )
                    
                    st.success("‚úÖ ƒê√£ t·∫°o b√°o c√°o v·ªõi th·ª© t·ª± ∆∞u ti√™n th√†nh c√¥ng!")
                
                elif report_format == "Excel ƒë∆°n gi·∫£n":
                    # T·∫°o file Excel ƒë∆°n gi·∫£n - S·ª¨ D·ª§NG aggregated_data
                    output_file = f'bao_cao_don_gian_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx'
                    with pd.ExcelWriter(output_file) as writer:
                        aggregated_data_export = aggregated_data.drop(columns=['Danh_m·ª•c_th·ª©_t·ª±', 'N·ªôi_dung_th·ª©_t·ª±'], errors='ignore')
                        aggregated_data_export.to_excel(writer, index=False)
                    
                    with open(output_file, 'rb') as f:
                        st.download_button(
                            "üì• T·∫£i Excel ƒë∆°n gi·∫£n",
                            f.read(),
                            output_file,
                            "application/vnd.ms-excel"
                        )
                    
                    st.success("‚úÖ ƒê√£ t·∫°o b√°o c√°o ƒë∆°n gi·∫£n th√†nh c√¥ng!")
                
                else:  # CSV
                    aggregated_data_export = aggregated_data.drop(columns=['Danh_m·ª•c_th·ª©_t·ª±', 'N·ªôi_dung_th·ª©_t·ª±'], errors='ignore')
                    csv = aggregated_data_export.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        "üì• T·∫£i CSV",
                        csv,
                        f"bao_cao_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        "text/csv"
                    )
                    
                    st.success("‚úÖ ƒê√£ t·∫°o file CSV th√†nh c√¥ng!")
    
    else:
        st.info("üëÜ Vui l√≤ng t·∫£i l√™n file Excel ho·∫∑c nh·∫≠p ƒë∆∞·ªùng d·∫´n file ƒë·ªÉ b·∫Øt ƒë·∫ßu")
        
        # H∆∞·ªõng d·∫´n
        with st.expander("üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng Dashboard Ph√≤ng H√†nh Ch√≠nh"):
            st.markdown("""
            ### üéØ Dashboard chuy√™n bi·ªát cho Ph√≤ng H√†nh Ch√≠nh
            
            #### ‚ú® **T√≠nh nƒÉng ƒë·∫∑c bi·ªát:**
            
            **1. Th·ª© t·ª± ∆∞u ti√™n c·ªë ƒë·ªãnh:**
            - ü•á T·ª± ƒë·ªông s·∫Øp x·∫øp theo th·ª© t·ª± quan tr·ªçng c√¥ng vi·ªác
            - üìã 13 danh m·ª•c ch√≠nh t·ª´ "VƒÉn b·∫£n ƒë·∫øn" ƒë·∫øn "B√£i gi·ªØ xe"
            - üìÑ 70 n·ªôi dung ƒë∆∞·ª£c s·∫Øp x·∫øp theo th·ª© t·ª± ∆∞u ti√™n
            
            **2. Hi·ªÉn th·ªã s·ªë ƒë·∫ßy ƒë·ªß:**
            - üí∞ Hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß s·ªë l·ªõn (v√≠ d·ª•: 1.234.567)
            - üìä B·∫£ng HTML t√πy ch·ªânh kh√¥ng b·ªã c·∫Øt s·ªë
            - üîç Scroll ngang ƒë·ªÉ xem ƒë·∫ßy ƒë·ªß d·ªØ li·ªáu
            
            **3. Bi·∫øn ƒë·ªông inline:**
            - üìà Gi√° tr·ªã v√† bi·∫øn ƒë·ªông trong c√πng m·ªôt √¥
            - üü¢ TƒÉng: "100.000 (‚Üë15%)" 
            - üî¥ Gi·∫£m: "85.000 (‚Üì15%)"
            - ‚ö™ Kh√¥ng ƒë·ªïi: "100.000 (‚Üí0%)"
            
            **4. Sync v·ªõi GitHub:**
            - ‚òÅÔ∏è T·ª± ƒë·ªông t·∫£i d·ªØ li·ªáu t·ª´ GitHub storage
            - üîÑ Upload v√† sync d·ªØ li·ªáu m·ªõi
            - üì± Truy c·∫≠p t·ª´ m·ªçi thi·∫øt b·ªã
            
            #### üìÇ **Danh m·ª•c theo th·ª© t·ª± ∆∞u ti√™n:**
            1. **VƒÉn b·∫£n ƒë·∫øn** - Qu·∫£n l√Ω vƒÉn b·∫£n ƒë·∫øn
            2. **VƒÉn b·∫£n ph√°t h√†nh** - Qu·∫£n l√Ω vƒÉn b·∫£n ƒëi
            3. **ChƒÉm s√≥c kh√°ch VIP** - D·ªãch v·ª• VIP
            4. **L·ªÖ t√¢n** - H·ªó tr·ª£ s·ª± ki·ªán
            5. **Ti·∫øp kh√°ch trong n∆∞·ªõc** - ƒê√≥n ti·∫øp kh√°ch
            6. **S·ª± ki·ªán** - T·ªï ch·ª©c s·ª± ki·ªán
            7. **ƒê√≥n ti·∫øp kh√°ch VIP** - D·ªãch v·ª• ƒë·∫∑c bi·ªát
            8. **T·ªï ch·ª©c cu·ªôc h·ªçp tr·ª±c tuy·∫øn** - H·ªçp online
            9. **Trang ƒëi·ªÅu h√†nh t√°c nghi·ªáp** - ƒêHTN
            10. **T·ªï xe** - Qu·∫£n l√Ω v·∫≠n t·∫£i
            11. **T·ªïng ƒë√†i** - D·ªãch v·ª• ƒëi·ªán tho·∫°i
            12. **H·ªá th·ªëng th∆∞ k√Ω B·ªánh vi·ªán** - Qu·∫£n l√Ω th∆∞ k√Ω
            13. **B√£i gi·ªØ xe** - D·ªãch v·ª• ƒë·∫≠u xe
            
            #### üöÄ **C√°ch s·ª≠ d·ª•ng:**
            1. **T·ª± ƒë·ªông**: D·ªØ li·ªáu t·ª± ƒë·ªông sync t·ª´ GitHub
            2. **Th·ªß c√¥ng**: Upload file Excel ho·∫∑c nh·∫≠p ƒë∆∞·ªùng d·∫´n n·∫øu c·∫ßn
            3. **Ch·ªçn b√°o c√°o**: Theo Tu·∫ßn/Th√°ng/Qu√Ω/NƒÉm
            4. **L·ªçc d·ªØ li·ªáu**: Ch·ªçn th·ªùi gian v√† danh m·ª•c
            5. **Xem k·∫øt qu·∫£**: Pivot table v·ªõi bi·∫øn ƒë·ªông inline
            6. **Xu·∫•t b√°o c√°o**: Excel/CSV v·ªõi th·ª© t·ª± ∆∞u ti√™n
            
            #### üí° **L·ª£i √≠ch:**
            - ‚ö° **T·ª± ƒë·ªông 100%**: Kh√¥ng c·∫ßn s·∫Øp x·∫øp th·ªß c√¥ng
            - üéØ **∆Øu ti√™n r√µ r√†ng**: Theo t·∫ßm quan tr·ªçng c√¥ng vi·ªác  
            - üìä **Hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß**: Kh√¥ng b·ªã m·∫•t s·ªë li·ªáu
            - üìà **Bi·∫øn ƒë·ªông tr·ª±c quan**: Nh√¨n th·∫•y ngay xu h∆∞·ªõng
            - üíæ **Xu·∫•t chuy√™n nghi·ªáp**: B√°o c√°o ƒë·∫ßy ƒë·ªß th√¥ng tin
            - ‚òÅÔ∏è **Sync t·ª± ƒë·ªông**: K·∫øt n·ªëi v·ªõi GitHub storage
            
            #### ‚ö†Ô∏è **L∆∞u √Ω:**
            - D·ªØ li·ªáu c·∫ßn c√≥ c·ªôt: Tu·∫ßn, Th√°ng, Danh m·ª•c, N·ªôi dung, S·ªë li·ªáu
            - Th·ª© t·ª± ∆∞u ti√™n ƒë√£ ƒë∆∞·ª£c c·ªë ƒë·ªãnh, kh√¥ng c·∫ßn ƒëi·ªÅu ch·ªânh
            - Bi·∫øn ƒë·ªông ch·ªâ hi·ªÉn th·ªã t·ª´ tu·∫ßn th·ª© 2 tr·ªü ƒëi
            - Bi·∫øn ƒë·ªông ƒë∆∞·ª£c t√≠nh so v·ªõi tu·∫ßn li·ªÅn tr∆∞·ªõc
            - D·ªØ li·ªáu s·∫Ω t·ª± ƒë·ªông sync t·ª´ GitHub n·∫øu c√≥ k·∫øt n·ªëi
            """)
            
        # Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n GitHub n·∫øu ch∆∞a k·∫øt n·ªëi
        if not connected:
            with st.expander("üîß C·∫•u h√¨nh GitHub ƒë·ªÉ sync t·ª± ƒë·ªông"):
                st.markdown("""
                **ƒê·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng sync t·ª± ƒë·ªông v·ªõi GitHub:**
                
                1. **T·∫°o GitHub Personal Access Token**:
                   - V√†o GitHub ‚Üí Settings ‚Üí Developer settings ‚Üí Personal access tokens
                   - T·∫°o token m·ªõi v·ªõi quy·ªÅn `repo` v√† `contents:write`
                
                2. **Th√™m v√†o Streamlit Secrets**:
                   ```
                   github_token = "ghp_xxxxxxxxxxxx"
                   github_owner = "your-username"  
                   github_repo = "your-repo-name"
                   ```
                
                3. **Sau khi c·∫•u h√¨nh**:
                   - Dashboard s·∫Ω t·ª± ƒë·ªông load d·ªØ li·ªáu t·ª´ GitHub
                   - Upload file m·ªõi tr·ª±c ti·∫øp l√™n GitHub
                   - Sync d·ªØ li·ªáu gi·ªØa c√°c thi·∫øt b·ªã
                """)

if __name__ == "__main__":
    main()